<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Problem Ⅱ: Linear Transformations | Shuhong Dai </title> <meta name="author" content="Shuhong Dai"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?6d57c5bac70ef6fae4bd96883a4eb4da"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shuhongdai.github.io/blog/2024/EC525_2/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <link defer rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css"> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script src="/assets/js/typograms.js?63f3caa50c7a9624f953b3aec207afa6"></script> <script>document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-typograms").forEach(e=>{const t=e.textContent,n=e.parentElement.parentElement;let a=document.createElement("pre");a.classList.add("typogram");const d=create("\n"+t,.3,!1);a.appendChild(d),n.appendChild(a),n.removeChild(e.parentElement)})});</script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Problem Ⅱ: Linear Transformations",
            "description": "",
            "published": "February 26, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shuhong</span> Dai </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Problem Ⅱ: Linear Transformations</h1> <p></p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#given-conditions">Given Conditions</a> </div> <div> <a href="#a-show-that-if-l-v-to-w-and-h-w-to-x-are-both-linear-maps-then-the-composition-h-circ-l-v-to-x-is-a-linear-map">（a) Show that if $L:V\to W$ and $H:W\to X$ are both linear maps, then the composition $H\circ L:V\to X$ is a linear map.</a> </div> <div> <a href="#b-show-vec-0-v-that-if-l-v-to-w-is-a-linear-map-then-l-vec-0-v-vec-0-w-where-vec-0-v-indicates-the-additive-identity-in-v-and-vec-0-w-indicates-the-additive-identity-in-w">(b) Show $\vec{0}_v$that if $L: V \to W$ is a linear map, then $L(\vec{0}_{V}) = \vec{0}_{W}$, where $\vec{0}_{V}$ indicates the additive identity in $V$ and $\vec{0}_{W}$ indicates the additive identity in $W$.</a> </div> <div> <a href="#c-the-kernel-of-a-linear-map-l-v-to-w-is-the-set-of-points-v-in-v-such-that-l-v-vec-0-w-show-that-a-linear-map-l-v-to-w-is-1-1-if-and-only-if-the-kernel-of-l-consists-of-only-the-identity-element-vec-0-v">(c) The kernel of a linear map $L:V\to W$ is the set of points $v\in V$ such that $L(v)=\vec{0}_{W}$. Show that a linear map $L:V\to W$ is 1-1 if and only if the kernel of $L$ consists of only the identity element $\vec{0}_{V}$.</a> </div> <div> <a href="#d-a-subspace-of-a-vector-space-v-is-a-subset-s-subset-v-such-that-for-all-v-w-in-s-v-w-in-s-and-for-all-v-in-s-and-c-in-mathbb-r-c-cdot-v-in-s-that-is-the-subspace-is-closed-under-the-addition-and-scalar-multiplication-operations-show-that-the-kernel-of-a-linear-map-l-v-to-w-forms-a-subspace-of-the-space-v">(d) A *subspace* of a vector space $V$ is a subset $S \subset V$ such that for all $v, w \in S$, $v + w \in S$ and for all $v \in S$ and $c \in \mathbb{R}$, $c \cdot v \in S$. That is, the subspace is *closed* under the addition and scalar multiplication operations. Show that the kernel of a linear map $L: V \to W$ forms a subspace of the space $V$.</a> </div> <div> <a href="#e-show-that-the-image-of-a-linear-map-l-v-to-w-is-a-subspace-of-w">(e) Show that the image of a linear map $L:V\to W$ is a subspace of $W$.</a> </div> <div> <a href="#f-the-set-of-linear-maps-from-v-to-w-is-typically-denoted-mathcal-l-v-w-define-an-addition-operation-on-linear-maps-as-follows-given-f-g-in-mathcal-l-v-w-set-k-f-g-by-k-v-f-v-g-v-where-the-addition-on-the-rhs-here-is-the-addition-operation-in-w-similarly-given-c-in-mathbb-r-we-define-a-scalar-multiplication-k-c-cdot-f-by-k-v-c-cdot-f-v-where-again-the-scalar-multiplication-is-the-operation-in-w-show-that-with-these-operations-mathcal-l-v-w-is-a-vector-space">(f) The set of linear maps from $V$ to $W$ is typically denoted $\mathcal{L}(V,W)$. Define an addition operation on linear maps as follows: given $F,G\in\mathcal{L}(V,W)$, set $K=F+G$ by $K(v)=F(v)+G(v)$, where the addition on the RHS here is the addition operation in $W$. Similarly, given $c\in\mathbb{R}$, we define a scalar multiplication $K=c\cdot F$ by $K(v)=c\cdot F(v)$, where again the scalar multiplication is the operation in $W$. Show that with these operations, $\mathcal{L}(V,W)$ is a vector space.</a> </div> </nav> </d-contents> <h2 id="given-conditions">Given Conditions</h2> <p>If $V$ and $W$ are two different vector spaces, a \textit{linear map} $L$ from $V$ to $W$ is a function $L:V\to W$ such that</p> <ul> <li>$L(v+v^{\prime})=L(v)+L(v^{\prime})$ for all $v,v^{\prime}\in V$.</li> <li>$L(s\cdot v)=s\cdot L(v)$ for all $s\in\mathbb{R}$, $v\in V$.</li> </ul> <p><strong>Quick Navigation</strong> ⬇️</p> <ul> <li> <p><a href="https://shuhongdai.github.io/blog/2023/EC525_0/">Preface: Motivation and Overview</a></p> </li> <li> <p><a href="https://shuhongdai.github.io/blog/2023/EC525_1/">Problem Ⅰ: Vector Spaces</a></p> </li> <li> <p><strong>Problem Ⅱ: Linear Transformations</strong> (You are currently browsing this post)</p> </li> <li> <p><a href="https://shuhongdai.github.io/blog/2024/EC525_3/">Problem Ⅲ: Group Theory</a></p> </li> <li> <p><a href="https://shuhongdai.github.io/blog/2024/EC525_4/">Problem Ⅳ: Dual Spaces and Functional Analysis</a></p> </li> <li> <p><a href="https://shuhongdai.github.io/blog/2024/EC525_5/">Problem Ⅴ: Infinite Sequences and Combinatorial Principles</a></p> </li> <li> <p><a href="https://shuhongdai.github.io/blog/2024/EC525_6/">Problem Ⅵ: Set Theory and Cardinality</a></p> </li> <li> <p><a href="https://shuhongdai.github.io/blog/2024/EC525_7/">Conclusion</a></p> </li> </ul> <hr> <h2 id="a-show-that-if-lvto-w-and-hwto-x-are-both-linear-maps-then-the-composition-hcirc-lvto-x-is-a-linear-map">（a) Show that if $L:V\to W$ and $H:W\to X$ are both linear maps, then the composition $H\circ L:V\to X$ is a linear map.</h2> <p><strong>Proposition 2.a.1.</strong> <em>Let $V, W, X$ be vector spaces over a field $\mathbb{R}$, and let $L: V \to W$ and $H: W \to X$ be linear maps. Then the composition $H \circ L: V \to X$ defined by $(H \circ L)(v) = H(L(v))$ for all $v \in V$ is linear.</em></p> <p><em>Proof.</em> By hypothesis, $L: V \to W$ is linear, hence for all $v_{1}, v_{2} \in V$ and all scalars $s \in \mathbb{R}$, the following identities hold:</p> \[L(v_{1} + v_{2}) = L(v_{1}) + L(v_{2}) \quad\text{and}\quad L(s \cdot v_{1}) = s \cdot L(v_{1}).\] <p>Similarly, since $H: W \to X$ is linear, for all $w_{1}, w_{2} \in W$ and all $t \in \mathbb{R}$, one has:</p> \[H(w_{1} + w_{2}) = H(w_{1}) + H(w_{2}) \quad\text{and}\quad H(t \cdot w_{1}) = t \cdot H(w_{1}).\] <p>To establish linearity of the composition $H \circ L: V \to X$, one must verify that for all $v_{1}, v_{2} \in V$ and all $r \in \mathbb{R}$, the following equalities hold:</p> \[(H \circ L)(v_{1} + v_{2}) = (H \circ L)(v_{1}) + (H \circ L)(v_{2}) \quad\text{and}\quad\] \[(H \circ L)(r \cdot v_{1}) = r \cdot (H \circ L)(v_{1}).\] <p>Consider arbitrary vectors $v_{1}, v_{2} \in V$. Since $H \circ L$ is defined by composition, one has</p> \[(H \circ L)(v_{1} + v_{2}) = H(L(v_{1} + v_{2})).\] <p>By linearity of $L$,</p> \[L(v_{1} + v_{2}) = L(v_{1}) + L(v_{2}),\] <p>thus</p> \[(H \circ L)(v_{1} + v_{2}) = H(L(v_{1}) + L(v_{2})).\] <p>Since $H$ is linear, it preserves addition, so</p> \[H(L(v_{1}) + L(v_{2})) = H(L(v_{1})) + H(L(v_{2})).\] <p>Substitute back the definition of composition:</p> \[H(L(v_{1})) + H(L(v_{2})) = (H \circ L)(v_{1}) + (H \circ L)(v_{2}).\] <p>Hence we have shown that for all $v_{1}, v_{2} \in V$,</p> \[(H \circ L)(v_{1} + v_{2}) = (H \circ L)(v_{1}) + (H \circ L)(v_{2}).\] <p>Next, consider an arbitrary vector $v \in V$ and an arbitrary scalar $r \in \mathbb{R}$. By the definition of composition,</p> \[(H \circ L)(r \cdot v) = H(L(r \cdot v)).\] <p>Since $L$ is linear, it respects scalar multiplication, yielding</p> \[L(r \cdot v) = r \cdot L(v).\] <p>Therefore,</p> \[(H \circ L)(r \cdot v) = H(r \cdot L(v)).\] <p>Because $H$ is linear, it also respects scalar multiplication, implying</p> \[H(r \cdot L(v)) = r \cdot H(L(v)).\] <p>Rewriting in terms of composition, this becomes</p> \[r \cdot H(L(v)) = r \cdot (H \circ L)(v).\] <p>Hence, for all $r \in \mathbb{R}$ and $v \in V$,</p> \[(H \circ L)(r \cdot v) = r \cdot (H \circ L)(v).\] <p>Both of the defining properties of linear maps, namely the preservation of vector addition and scalar multiplication, have been verified for the map $H \circ L$. Consequently, $H \circ L$ is linear. $\textbf{Q.E.D.}$</p> <blockquote> <p><strong>Commentary</strong></p> <p>The essential elements of the proof rest on the axioms of linearity, which are stable under composition. Thus, the space of linear maps between vector spaces is closed under composition.</p> </blockquote> <hr> <h2 id="b-show-vec0_vthat-if-l-v-to-w-is-a-linear-map-then-lvec0_v--vec0_w-where-vec0_v-indicates-the-additive-identity-in-v-and-vec0_w-indicates-the-additive-identity-in-w">(b) Show $\vec{0}_v$that if $L: V \to W$ is a linear map, then $L(\vec{0}_{V}) = \vec{0}_{W}$, where $\vec{0}_{V}$ indicates the additive identity in $V$ and $\vec{0}_{W}$ indicates the additive identity in $W$.</h2> <p><strong>Proposition 2.b.1.</strong> <em>Let $V$ and $W$ be vector spaces over the field $\mathbb{R}$, and let $L: V \to W$ be a linear map. Then $L(\vec{0}_V) = \vec{0}_W$, where $\vec{0}_V$ and $\vec{0}_W$ denote the additive identities in $V$ and $W$, respectively.</em></p> <p><em>Proof.</em> By the definition of a linear map, $L$ satisfies the following properties for all vectors $v, v’ \in V$ and all scalars $s \in \mathbb{R}$:</p> \[L(v + v') = L(v) + L(v') \quad \text{and} \quad L(s \cdot v) = s \cdot L(v).\] <p>In particular, consider the vector $\vec{0}_V$, the additive identity in $V$. By the property of additive identities in vector spaces, for any vector $v \in V$, we have:</p> \[v + \vec{0}_V = v.\] <p>Applying the linear map $L$ to both sides of this equation yields: \(L(v + \vec{0}_V) = L(v).\) Using the additivity of $L$, the left-hand side can be expressed as:</p> \[L(v + \vec{0}_V) = L(v) + L(\vec{0}_V).\] <p>Thus, we have:</p> \[L(v) + L(\vec{0}_V) = L(v).\] <p>To isolate $L(\vec{0}_V)$, subtract $L(v)$ from both sides:</p> \[L(v) + L(\vec{0}_V) - L(v) = L(v) - L(v).\] <p>Simplifying both sides, we obtain:</p> \[L(\vec{0}_V) = \vec{0}_W,\] <p>where $\vec{0}_W$ is the additive identity in $W$, since the only element in $W$ that satisfies $w + \vec{0}_W = w$ for all $w \in W$ is $\vec{0}_W$ itself.</p> <p>Alternatively, one may employ the homogeneity property of linear maps. Consider the scalar multiplication by zero, which yields:</p> \[L(0 \cdot v) = 0 \cdot L(v).\] <p>Since $0 \cdot v = \vec{0}_V$ for any $v \in V$, and $0 \cdot L(v) = \vec{0}_W$ in $W$, it follows that:</p> \[L(\vec{0}_V) = \vec{0}_W.\] <p>$\textbf{Q.E.D.}$</p> <hr> <h2 id="c-the-kernel-of-a-linear-map-lvto-w-is-the-set-of-points-vin-v-such-that-lvvec0_w-show-that-a-linear-map-lvto-w-is-1-1-if-and-only-if-the-kernel-of-l-consists-of-only-the-identity-element-vec0_v">(c) The kernel of a linear map $L:V\to W$ is the set of points $v\in V$ such that $L(v)=\vec{0}_{W}$. Show that a linear map $L:V\to W$ is 1-1 if and only if the kernel of $L$ consists of only the identity element $\vec{0}_{V}$.</h2> <p><strong>Proposition 2.c.1.</strong> <em>Let $V$ and $W$ be vector spaces over the field $\mathbb{R}$, and let $L: V \to W$ be a linear transformation. Then $L$ is injective (one-to-one) if and only if the kernel of $L$, denoted by $\ker(L)$, consists solely of the zero vector in $V$, that is, $\ker(L) = { \vec{0}_V }$.</em></p> <p><em>Proof.</em> We proceed by establishing both implications of the equivalence:</p> <ol> <li>Necessity: If $L$ is injective, then $\ker(L) = { \vec{0}_V }$.</li> <li>Sufficiency: If $\ker(L) = { \vec{0}_V }$, then $L$ is injective.</li> </ol> <p>Necessity: Assume that $L: V \to W$ is injective. We aim to show that $\ker(L) = { \vec{0}_V }$.</p> <p>By definition, the kernel of $L$ is the set:</p> \[\ker(L) = \{ v \in V \vert L(v) = \vec{0}_W \}.\] <p>To demonstrate that $\ker(L) = { \vec{0}_V }$, we must show two inclusions:</p> \[\ker(L) \subseteq \{ \vec{0}_V \} \quad \text{and} \quad \{ \vec{0}_V \} \subseteq \ker(L).\] <p>The second inclusion is trivial since $L(\vec{0}_V) = \vec{0}_W$ by the linearity of $L$ (as established in Proposition 2.b.1).</p> <p>For the first inclusion, suppose $v \in \ker(L)$. Then, by definition:</p> \[L(v) = \vec{0}_W.\] <p>Given that $L$ is injective, the only solution to $L(v) = \vec{0}_W$ is $v = \vec{0}_V$. To see this, consider the injectivity of $L$, which implies that if $L(v) = L(v’)$, then $v = v’$. Specifically, taking $v’ = \vec{0}_V$, we have:</p> \[L(v) = \vec{0}_W = L(\vec{0}_V) \implies v = \vec{0}_V.\] <p>Thus, $v$ must be the zero vector in $V$, and therefore:</p> \[\ker(L) \subseteq \{ \vec{0}_V \}.\] <p>Combining both inclusions, we conclude:</p> \[\ker(L) = \{ \vec{0}_V \}.\] <p>This establishes the necessity part of the proposition.</p> <p>Sufficiency: Now, assume that $\ker(L) = { \vec{0}_V }$. We aim to demonstrate that $L$ is injective.</p> <p>To prove that $L$ is injective, we must show that for any $v_1, v_2 \in V$, if $L(v_1) = L(v_2)$, then $v_1 = v_2$.</p> <p>Consider arbitrary vectors $v_1, v_2 \in V$ such that:</p> \[L(v_1) = L(v_2).\] <p>Subtracting $L(v_2)$ from both sides yields:</p> \[L(v_1) - L(v_2) = \vec{0}_W.\] <p>Utilizing the linearity of $L$, this can be rewritten as:</p> \[L(v_1 - v_2) = \vec{0}_W.\] <p>By the definition of the kernel, this implies:</p> \[v_1 - v_2 \in \ker(L).\] <p>Given that $\ker(L) = { \vec{0}_V }$, it follows that:</p> \[v_1 - v_2 = \vec{0}_V.\] <p>Thus, we conclude:</p> \[v_1 = v_2.\] <p>This establishes that $L$ is injective, as required. $\textbf{Q.E.D.}$</p> <hr> <h2 id="d-a-subspace-of-a-vector-space-v-is-a-subset-s-subset-v-such-that-for-all-v-w-in-s-v--w-in-s-and-for-all-v-in-s-and-c-in-mathbbr-c-cdot-v-in-s-that-is-the-subspace-is-closed-under-the-addition-and-scalar-multiplication-operations-show-that-the-kernel-of-a-linear-map-l-v-to-w-forms-a-subspace-of-the-space-v">(d) A <em>subspace</em> of a vector space $V$ is a subset $S \subset V$ such that for all $v, w \in S$, $v + w \in S$ and for all $v \in S$ and $c \in \mathbb{R}$, $c \cdot v \in S$. That is, the subspace is <em>closed</em> under the addition and scalar multiplication operations. Show that the kernel of a linear map $L: V \to W$ forms a subspace of the space $V$.</h2> <p><strong>Proposition 2.d.1</strong> <em>Let $V$ and $W$ be vector spaces over the field $\mathbb{R}$, and let $L: V \to W$ be a linear transformation. Then the kernel of $L$, denoted by $\ker(L)$, defined as</em></p> \[\ker(L) = \{ v \in V \vert L(v) = \vec{0}_W \},\] <p><em>is a subspace of $V$.</em></p> <p><em>Proof.</em> To establish that $\ker(L)$ is a subspace of $V$, we must verify that $\ker(L)$ satisfies the three axioms defining a subspace within a vector space. Specifically, we need to confirm that:</p> <ol> <li>$\ker(L)$ is non-empty.</li> <li>$\ker(L)$ is closed under vector addition.</li> <li>$\ker(L)$ is closed under scalar multiplication.</li> </ol> <p>We proceed by verifying each of these properties in turn.</p> <p>Non-emptiness of $\ker(L)$: By definition, a subspace must contain the zero vector of the ambient vector space. Consider the additive identity $\vec{0}_V \in V$. Applying the linear transformation $L$ to $\vec{0}_V$, we obtain:</p> \[L(\vec{0}_V) = \vec{0}_W,\] <p>as established in Proposition 2.b.1. Therefore, $\vec{0}_V \in \ker(L)$, which implies that $\ker(L)$ is non-empty.</p> <p>Closure under Vector Addition: Let $u, v \in \ker(L)$. By the definition of the kernel, this means:</p> \[L(u) = \vec{0}_W \quad \text{and} \quad L(v) = \vec{0}_W.\] <p>We must show that $u + v \in \ker(L)$, i.e., $L(u + v) = \vec{0}_W$.</p> <p>Applying the linearity of $L$, we have:</p> \[L(u + v) = L(u) + L(v).\] <p>Substituting the known values from the kernel, this becomes:</p> \[L(u + v) = \vec{0}_W + \vec{0}_W = \vec{0}_W.\] <p>Thus, $u + v \in \ker(L)$, establishing closure under vector addition.</p> <p>Closure under Scalar Multiplication: Let $v \in \ker(L)$ and let $c \in \mathbb{R}$ be an arbitrary scalar. We must demonstrate that $c \cdot v \in \ker(L)$, i.e., $L(c \cdot v) = \vec{0}_W$.</p> <p>Applying the linearity of $L$ with respect to scalar multiplication, we obtain:</p> \[L(c \cdot v) = c \cdot L(v).\] <p>Since $v \in \ker(L)$, it follows that $L(v) = \vec{0}_W$. Substituting this into the equation above yields:</p> \[L(c \cdot v) = c \cdot \vec{0}_W = \vec{0}_W.\] <p>Therefore, $c \cdot v \in \ker(L)$, establishing closure under scalar multiplication. $\textbf{Q.E.D.}$</p> <hr> <h2 id="e-show-that-the-image-of-a-linear-map-lvto-w-is-a-subspace-of-w">(e) Show that the image of a linear map $L:V\to W$ is a subspace of $W$.</h2> <p><strong>Proposition 2.e.1.</strong> <em>Let $V$ and $W$ be vector spaces over the field $\mathbb{R}$, and let $L: V \to W$ be a linear map. Then the image of $L$, defined by \(\text{Im}(L) = \{ L(v) \mid v \in V \},\) is a subspace of $W$.</em></p> <p><em>Proof.</em> To establish that $\text{Im}(L)$ is a subspace of $W$, it is necessary to verify that it satisfies the three axioms defining a subspace. Specifically, we must demonstrate that:</p> <ol> <li>The zero vector $\vec{0}_W$ of $W$ is an element of $\text{Im}(L)$.</li> <li>$\text{Im}(L)$ is closed under vector addition.</li> <li>$\text{Im}(L)$ is closed under scalar multiplication.</li> </ol> <p>Containment of the Zero Vector: By the linearity of $L$, for any vector space $V$, the map $L$ satisfies</p> \[L(\vec{0}_V) = \vec{0}_W.\] <p>Here, $\vec{0}_V$ denotes the additive identity in $V$, and $\vec{0}_W$ denotes the additive identity in $W$. Since $\vec{0}_V \in V$, it follows directly from the definition of the image that</p> \[\vec{0}_W = L(\vec{0}_V) \in \text{Im}(L).\] <p>Thus, the zero vector of $W$ is contained within $\text{Im}(L)$.</p> <p>Closure Under Vector Addition: Let $u, v \in \text{Im}(L)$. By the definition of the image, there exist vectors $u’, v’ \in V$ such that</p> \[u = L(u') \quad \text{and} \quad v = L(v').\] <p>Consider the sum $u + v$ in $W$. Applying the linearity of $L$, we have</p> \[u + v = L(u') + L(v') = L(u' + v').\] <p>Since $u’ + v’ \in V$ (as $V$ is a vector space and thus closed under addition), it follows that</p> \[u + v = L(u' + v') \in \text{Im}(L).\] <p>Therefore, $\text{Im}(L)$ is closed under vector addition.</p> <p>Closure Under Scalar Multiplication: Let $v \in \text{Im}(L)$ and let $c \in \mathbb{R}$ be an arbitrary scalar. By the definition of the image, there exists a vector $v’ \in V$ such that</p> \[v = L(v').\] <p>Consider the scalar multiple $c \cdot v$ in $W$. Utilizing the linearity of $L$, we obtain</p> \[c \cdot v = c \cdot L(v') = L(c \cdot v').\] <p>Since $c \cdot v’ \in V$ (as $V$ is a vector space and thus closed under scalar multiplication), it follows that</p> \[c \cdot v = L(c \cdot v') \in \text{Im}(L).\] <p>Hence, $\text{Im}(L)$ is closed under scalar multiplication. $\textbf{Q.E.D.}$</p> <hr> <h2 id="f-the-set-of-linear-maps-from-v-to-w-is-typically-denoted-mathcallvw-define-an-addition-operation-on-linear-maps-as-follows-given-fginmathcallvw-set-kfg-by-kvfvgv-where-the-addition-on-the-rhs-here-is-the-addition-operation-in-w-similarly-given-cinmathbbr-we-define-a-scalar-multiplication-kccdot-f-by-kvccdot-fv-where-again-the-scalar-multiplication-is-the-operation-in-w-show-that-with-these-operations-mathcallvw-is-a-vector-space">(f) The set of linear maps from $V$ to $W$ is typically denoted $\mathcal{L}(V,W)$. Define an addition operation on linear maps as follows: given $F,G\in\mathcal{L}(V,W)$, set $K=F+G$ by $K(v)=F(v)+G(v)$, where the addition on the RHS here is the addition operation in $W$. Similarly, given $c\in\mathbb{R}$, we define a scalar multiplication $K=c\cdot F$ by $K(v)=c\cdot F(v)$, where again the scalar multiplication is the operation in $W$. Show that with these operations, $\mathcal{L}(V,W)$ is a vector space.</h2> <p><strong>Proposition 2.f.1.</strong> <em>Let $V$ and $W$ be vector spaces over the field $\mathbb{R}$. Define the set $\mathcal{L}(V, W)$ to consist of all linear maps from $V$ to $W$. Equip $\mathcal{L}(V, W)$ with the operations of addition and scalar multiplication as defined below:</em></p> \[(F + G)(v) = F(v) + G(v) \quad \text{for all } F, G \in \mathcal{L}(V, W) \text{ and } v \in V,\] \[(c \cdot F)(v) = c \cdot F(v) \quad \text{for all } F \in \mathcal{L}(V, W), \, c \in \mathbb{R}, \text{ and } v \in V.\] <p><em>Then $\mathcal{L}(V, W)$ endowed with these operations constitutes a vector space over $\mathbb{R}$.</em></p> <p><em>Proof.</em> To establish that $\mathcal{L}(V, W)$ constitutes a vector space under the defined operations of addition and scalar multiplication, it is requisite to verify that it adheres to all the fundamental axioms that characterize a vector space. Specifically, we will verify the following properties:</p> <ol> <li> <p>Closure under Addition: For all $F, G \in \mathcal{L}(V, W)$, the map $F + G$ defined by $(F + G)(v) = F(v) + G(v)$ for all $v \in V$ is also an element of $\mathcal{L}(V, W)$.</p> </li> <li> <p>Closure under Scalar Multiplication: For all $F \in \mathcal{L}(V, W)$ and $c \in \mathbb{R}$, the map $c \cdot F$ defined by $(c \cdot F)(v) = c \cdot F(v)$ for all $v \in V$ is also an element of $\mathcal{L}(V, W)$.</p> </li> <li> <p>Associativity of Addition: For all $F, G, H \in \mathcal{L}(V, W)$, $(F + G) + H = F + (G + H)$.</p> </li> <li> <p>Commutativity of Addition: For all $F, G \in \mathcal{L}(V, W)$, $F + G = G + F$.</p> </li> <li> <p>Existence of Additive Identity: There exists a linear map $\Theta \in \mathcal{L}(V, W)$ such that for all $F \in \mathcal{L}(V, W)$, $F + \Theta = F$.</p> </li> <li> <p>Existence of Additive Inverses: For each $F \in \mathcal{L}(V, W)$, there exists a linear map $-F \in \mathcal{L}(V, W)$ such that $F + (-F) = \Theta$.</p> </li> <li> <p>Distributivity of Scalar Multiplication with Respect to Vector Addition: For all $c \in \mathbb{R}$ and $F, G \in \mathcal{L}(V, W)$, $c \cdot (F + G) = c \cdot F + c \cdot G$.</p> </li> <li> <p>Distributivity of Scalar Multiplication with Respect to Field Addition: For all $c, d \in \mathbb{R}$ and $F \in \mathcal{L}(V, W)$, $(c + d) \cdot F = c \cdot F + d \cdot F$.</p> </li> <li> <p>Compatibility of Scalar Multiplication with Field Multiplication: For all $c, d \in \mathbb{R}$ and $F \in \mathcal{L}(V, W)$, $c \cdot (d \cdot F) = (c d) \cdot F$.</p> </li> <li> <p>Identity Element of Scalar Multiplication: For the scalar $1 \in \mathbb{R}$ and for all $F \in \mathcal{L}(V, W)$, $1 \cdot F = F$.</p> </li> </ol> <p>Closure under Addition: Let $F, G \in \mathcal{L}(V, W)$. We must show that $F + G$ is a linear map from $V$ to $W$, i.e., $F + G \in \mathcal{L}(V, W)$.</p> <p>Additivity: For all $v_1, v_2 \in V$,</p> \[(F + G)(v_1 + v_2) = F(v_1 + v_2) + G(v_1 + v_2).\] <p>Since $F$ and $G$ are linear maps,</p> \[F(v_1 + v_2) = F(v_1) + F(v_2),\] \[G(v_1 + v_2) = G(v_1) + G(v_2).\] <p>Thus,</p> \[(F + G)(v_1 + v_2) = [F(v_1) + F(v_2)] + [G(v_1) + G(v_2)]\] \[= [F(v_1) + G(v_1)] + [F(v_2) + G(v_2)] = (F + G)(v_1) + (F + G)(v_2).\] <p>Homogeneity: For all $c \in \mathbb{R}$ and $v \in V$,</p> \[(F + G)(c \cdot v) = F(c \cdot v) + G(c \cdot v).\] <p>Again, since $F$ and $G$ are linear maps,</p> \[F(c \cdot v) = c \cdot F(v),\] \[G(c \cdot v) = c \cdot G(v).\] <p>Thus,</p> \[(F + G)(c \cdot v) = c \cdot F(v) + c \cdot G(v) = c \cdot [F(v) + G(v)] = c \cdot (F + G)(v).\] <p>Therefore, $F + G$ preserves both vector addition and scalar multiplication, and hence $F + G$ is linear. Consequently, $F + G \in \mathcal{L}(V, W)$, establishing closure under addition.</p> <p>Closure under Scalar Multiplication: Let $F \in \mathcal{L}(V, W)$ and $c \in \mathbb{R}$. We must show that $c \cdot F$ is a linear map from $V$ to $W$, i.e., $c \cdot F \in \mathcal{L}(V, W)$.</p> <p>Additivity: For all $v_1, v_2 \in V$,</p> \[(c \cdot F)(v_1 + v_2) = c \cdot F(v_1 + v_2).\] <p>Since $F$ is linear,</p> \[F(v_1 + v_2) = F(v_1) + F(v_2).\] <p>Thus,</p> \[(c \cdot F)(v_1 + v_2) = c \cdot [F(v_1) + F(v_2)] = c \cdot F(v_1) + c \cdot F(v_2) = (c \cdot F)(v_1) + (c \cdot F)(v_2).\] <p>Homogeneity: For all $d \in \mathbb{R}$ and $v \in V$,</p> \[(c \cdot F)(d \cdot v) = c \cdot F(d \cdot v).\] <p>Since $F$ is linear,</p> \[F(d \cdot v) = d \cdot F(v).\] <p>Thus,</p> \[(c \cdot F)(d \cdot v) = c \cdot [d \cdot F(v)] = (c d) \cdot F(v) = d \cdot (c \cdot F)(v).\] <p>Therefore, $c \cdot F$ preserves both vector addition and scalar multiplication, and hence $c \cdot F$ is linear. Consequently, $c \cdot F \in \mathcal{L}(V, W)$, establishing closure under scalar multiplication.</p> <p>Associativity of Addition: Let $F, G, H \in \mathcal{L}(V, W)$. We must show that $(F + G) + H = F + (G + H)$.</p> <p>For all $v \in V$,</p> \[[(F + G) + H](v) = (F + G)(v) + H(v) = [F(v) + G(v)] + H(v) =\] \[F(v) + [G(v) + H(v)] = F(v) + (G + H)(v) = [F + (G + H)](v).\] <p>Since this holds for all $v \in V$, we conclude that $(F + G) + H = F + (G + H)$.</p> <p>Commutativity of Addition: Let $F, G \in \mathcal{L}(V, W)$. We must show that $F + G = G + F$.</p> <p>For all $v \in V$,</p> \[(F + G)(v) = F(v) + G(v) = G(v) + F(v) = (G + F)(v).\] <p>Since this holds for all $v \in V$, we conclude that $F + G = G + F$.</p> <p>Existence of Additive Identity: We must exhibit an element $\Theta \in \mathcal{L}(V, W)$ such that for all $F \in \mathcal{L}(V, W)$, $F + \Theta = F$.</p> <p>Define $\Theta: V \to W$ by $\Theta(v) = \vec{0}_W$ for all $v \in V$, where $\vec{0}_W$ is the zero vector in $W$.</p> <p>Linearity of $\Theta$: For all $v_1, v_2 \in V$ and $c \in \mathbb{R}$,</p> \[\Theta(v_1 + v_2) = \vec{0}_W = \vec{0}_W + \vec{0}_W = \Theta(v_1) + \Theta(v_2),\] \[\Theta(c \cdot v) = \vec{0}_W = c \cdot \vec{0}_W = c \cdot \Theta(v).\] <p>Thus, $\Theta$ is linear, and hence $\Theta \in \mathcal{L}(V, W)$.</p> <p>Additive Identity Property: For all $F \in \mathcal{L}(V, W)$ and $v \in V$,</p> \[(F + \Theta)(v) = F(v) + \Theta(v) = F(v) + \vec{0}_W = F(v).\] <p>Therefore, $F + \Theta = F$ for all $F \in \mathcal{L}(V, W)$, establishing the existence of an additive identity in $\mathcal{L}(V, W)$.</p> <p>Existence of Additive Inverses: For each $F \in \mathcal{L}(V, W)$, we must exhibit a linear map $-F \in \mathcal{L}(V, W)$ such that $F + (-F) = \Theta$, where $\Theta$ is the additive identity in $\mathcal{L}(V, W)$.</p> <p>Define $-F: V \to W$ by $(-F)(v) = -F(v)$ for all $v \in V$.</p> <p>Linearity of $-F$: For all $v_1, v_2 \in V$ and $c \in \mathbb{R}$,</p> \[(-F)(v_1 + v_2) = -F(v_1 + v_2) = -[F(v_1) + F(v_2)] =\] \[-F(v_1) - F(v_2) = (-F)(v_1) + (-F)(v_2),\] \[(-F)(c \cdot v) = -F(c \cdot v) = -[c \cdot F(v)] = c \cdot (-F(v)) = c \cdot (-F)(v).\] <p>Thus, $-F$ is linear, and hence $-F \in \mathcal{L}(V, W)$.</p> <p>Additive Inverse Property: For all $F \in \mathcal{L}(V, W)$ and $v \in V$,</p> \[(F + (-F))(v) = F(v) + (-F)(v) = F(v) - F(v) = \vec{0}_W = \Theta(v).\] <p>Therefore, $F + (-F) = \Theta$, establishing the existence of additive inverses in $\mathcal{L}(V, W)$.</p> <p>Distributivity of Scalar Multiplication with Respect to Vector Addition: Let $c \in \mathbb{R}$ and $F, G \in \mathcal{L}(V, W)$. We must show that</p> \[c \cdot (F + G) = c \cdot F + c \cdot G.\] <p>For all $v \in V$,</p> \[[c \cdot (F + G)](v) = c \cdot (F + G)(v) = c \cdot [F(v) + G(v)] =\] \[c \cdot F(v) + c \cdot G(v) = [c \cdot F](v) + [c \cdot G](v) = [c \cdot F + c \cdot G](v).\] <p>Since this holds for all $v \in V$, we conclude that $c \cdot (F + G) = c \cdot F + c \cdot G$.</p> <p>Distributivity of Scalar Multiplication with Respect to Field Addition: Let $c, d \in \mathbb{R}$ and $F \in \mathcal{L}(V, W)$. We must show that</p> \[(c + d) \cdot F = c \cdot F + d \cdot F.\] <p>For all $v \in V$,</p> \[[(c + d) \cdot F](v) = (c + d) \cdot F(v) = c \cdot F(v) + d \cdot F(v) =\] \[[c \cdot F](v) + [d \cdot F](v) = [c \cdot F + d \cdot F](v).\] <p>Since this holds for all $v \in V$, we conclude that $(c + d) \cdot F = c \cdot F + d \cdot F$.</p> <p>Compatibility of Scalar Multiplication with Field Multiplication: Let $c, d \in \mathbb{R}$ and $F \in \mathcal{L}(V, W)$. We must show that</p> \[c \cdot (d \cdot F) = (c d) \cdot F.\] <p>For all $v \in V$,</p> \[[c \cdot (d \cdot F)](v) = c \cdot [d \cdot F(v)] = (c d) \cdot F(v) = [(c d) \cdot F](v).\] <p>Since this holds for all $v \in V$, we conclude that $c \cdot (d \cdot F) = (c d) \cdot F$.</p> <p>Identity Element of Scalar Multiplication: Let $F \in \mathcal{L}(V, W)$. We must show that</p> \[1 \cdot F = F.\] <p>For all $v \in V$,</p> \[[1 \cdot F](v) = 1 \cdot F(v) = F(v).\] <p>Thus, $1 \cdot F = F$. $\textbf{Q.E.D.}$</p> <blockquote> <p><strong>Commentray</strong></p> <p>In infinite-dimensional settings, while some properties may differ, the vector space structure of $\mathcal{L}(V, W)$ remains valid as long as operations are well-defined.</p> </blockquote> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Shuhong Dai. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"post-maximal-entropy-of-the-boltzmann-distribution-a-quantum-perspective",title:"Maximal Entropy of the Boltzmann Distribution: A Quantum Perspective",description:"Specifically, in the classical limit (when \u03b2En &lt;&lt; 1), the quantum energy levels become very close to each other, and the partition function can be approximated by an integral over continuous energy states rather than a sum over discrete states. In this limit, the quantum Boltzmann distribution approaches the classical result...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Boltzmann/"}},{id:"post-a-sketch-of-proofs-for-some-properties-of-multivariate-gaussian-distribution",title:"A Sketch of Proofs for Some Properties of Multivariate Gaussian Distribution",description:"When we diagonalize the covariance matrix, we essentially rotate the space such that the axes align with the principal directions of variation...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Proofs-for-Some-Properties/"}},{id:"post-is-the-transition-from-univariate-to-multivariate-gaussian-distribution-linear",title:"Is the Transition from Univariate to Multivariate Gaussian Distribution Linear?",description:"Now that we have the foundation in place, let\u2019s shift gears and consider the generalization of the univariate Gaussian to higher dimensions. In the multivariate case, we are no longer dealing with a single random variable, but rather a vector of random variables...",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate_Gaussian_distribution/"}},{id:"post-a-supplementary-discussion-on-correlation-coefficients",title:"A Supplementary Discussion on Correlation Coefficients",description:"Yet covariance itself is sensitive to the original units of measurement, limiting its direct interpretability across different data scales...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Correlation_Coefficients/"}},{id:"post-an-introductory-look-at-covariance-and-the-mean-vector",title:"An Introductory Look at Covariance and the Mean Vector",description:"If the mean vector gives us a sense of location, then the covariance matrix gives us a sense of shape...",section:"Posts",handler:()=>{window.location.href="/blog/2024/An_Introductory_Look_at_Covariance_and_the_Mean_Vector/"}},{id:"post-problem-dual-spaces-and-functional-analysis",title:"Problem \u2163: Dual Spaces and Functional Analysis",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/EC525_4/"}},{id:"post-sampling-smarter-unlocking-the-power-of-latin-hypercube-sampling",title:"Sampling Smarter: Unlocking the Power of Latin Hypercube Sampling",description:"Unlike random sampling, which might leave some regions underrepresented while others get chosen repeatedly...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Latin_Hypercube_Sampling/"}},{id:"post-problem-group-theory",title:"Problem \u2162: Group Theory",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/EC525_3/"}},{id:"post-problem-linear-transformations",title:"Problem \u2161: Linear Transformations",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/EC525_2/"}},{id:"post-problem-vector-spaces",title:"Problem \u2160: Vector Spaces",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/EC525_1/"}},{id:"post-preface-motivation-and-overview",title:"Preface: Motivation and Overview",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/EC525_0/"}},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-won-the-1st-prize-with-a-designed-four-switch-buck-boost-circuit-in-the-university-electronic-design-competition-sponsored-by-huawei",title:"Won the 1st prize with a designed four-switch buck-boost circuit in the university...",description:"",section:"News"},{id:"news-received-the-first-class-academic-scholarship",title:"Received the First-Class Academic Scholarship.",description:"",section:"News"},{id:"news-won-the-3rd-prize-for-problem-g-quot-non-contact-object-measurement-device-quot-at-the-8th-national-undergraduate-electronics-indesign-contest",title:"Won the 3rd prize for Problem G: &quot;Non-contact Object Measurement Device&quot; at the...",description:"",section:"News"},{id:"news-visited-the-key-laboratory-of-advanced-energy-traction-and-comprehensive-energy-saving-railway-industry-at-swjtu",title:"Visited the Key Laboratory of Advanced Energy Traction and Comprehensive Energy Saving Railway...",description:"",section:"News"},{id:"news-received-the-first-class-academic-scholarship",title:"Received the First-Class Academic Scholarship.",description:"",section:"News"},{id:"news-won-the-3rd-prize-in-problem-b-quot-ethanol-coupling-to-produce-c4-olefins-quot-at-the-30th-china-undergraduate-mathematical-contest-in-modeling",title:"Won the 3rd prize in Problem B: &quot;Ethanol Coupling to Produce C4 Olefins&quot;...",description:"",section:"News"},{id:"news-won-the-1st-prize-in-the-preliminary-national-round-of-the-5th-chinese-education-cup-mathematics-competition",title:"Won the 1st prize in the preliminary national round of the 5th Chinese...",description:"",section:"News"},{id:"news-won-the-2nd-prize-in-the-national-finals-of-the-5th-chinese-education-cup-mathematics-competition",title:"Won the 2nd prize in the national finals of the 5th Chinese Education...",description:"",section:"News"},{id:"news-won-the-1st-prize-at-the-provincial-level-in-the-13th-chinese-mathematics-competitions",title:"Won the 1st prize at the provincial level in the 13th Chinese Mathematics...",description:"",section:"News"},{id:"news-guided-the-quot-dual-car-following-system-quot-project-which-won-the-highest-award-the-quot-ti-cup-quot-in-the-10th-national-undergraduate-electronics-design-contest",title:"Guided the &quot;Dual-Car Following System&quot; project which won the highest award, the &quot;TI...",description:"",section:"News"},{id:"news-obtained-my-bachelor-39-s-degree-in-electrical-engineering",title:"Obtained my Bachelor&#39;s Degree in Electrical Engineering.",description:"",section:"News"},{id:"news-joined-the-distributed-systems-group-at-ncepu-to-pursue-my-master-39-s-degree-in-computer-science",title:"Joined the Distributed Systems Group at NCEPU to pursue my Master&#39;s degree in...",description:"",section:"News"},{id:"news-participated-in-world-robot-conference-2024-in-beijing",title:"Participated in World Robot Conference 2024 in Beijing.",description:"",section:"News"},{id:"news-a-paper-on-data-compression-for-transportation-https-ieeexplore-ieee-org-document-10376424-was-accepted-by-ieee-iot-journal",title:"[A paper on data compression for transportation](https://ieeexplore.ieee.org/document/10376424) was accepted by _IEEE IoT Journal_....",description:"",section:"News"},{id:"news-a-paper-on-energy-efficient-computing-https-www-sciencedirect-com-science-article-pii-s0140366423004802-via-3dihub-was-accepted-by-computer-communications",title:"[A paper on energy-efficient computing](https://www.sciencedirect.com/science/article/pii/S0140366423004802?via%3Dihub) was accepted by _Computer Communications_.",description:"",section:"News"},{id:"news-participated-in-microsoft-ai-day-beijing",title:"Participated in Microsoft AI Day Beijing.",description:"",section:"News"},{id:"news-a-paper-on-vehicle-road-cooperation-https-ieeexplore-ieee-org-document-10632106-was-accepted-by-ieee-iot-journal",title:"[A paper on vehicle-road cooperation](https://ieeexplore.ieee.org/document/10632106) was accepted by _IEEE IoT Journal_.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%61%69%73%68%75%68%6F%6E%67%30%32@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0009-0004-4910-182X","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=lwCWmPUAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>