<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="3hx6hRZ1EJWUbqkkXZ-vPQfpV0JdKNKT_aKcRjSixr0"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Sampling Smarter: Unlocking the Power of Latin Hypercube Sampling | Shuhong Dai </title> <meta name="author" content="Shuhong Dai"> <meta name="description" content="Unlike random sampling, which might leave some regions underrepresented while others get chosen repeatedly..."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon.png?6d57c5bac70ef6fae4bd96883a4eb4da"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shuhongdai.github.io/blog/2024/Latin_Hypercube_Sampling/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shuhong</span> Dai </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Sampling Smarter: Unlocking the Power of Latin Hypercube Sampling</h1> <p class="post-meta"> Created in May 03, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> Statistics</a>   <a href="/blog/tag/probability-theory"> <i class="fa-solid fa-hashtag fa-sm"></i> Probability Theory</a>   ·   <a href="/blog/category/bits-and-pieces"> <i class="fa-solid fa-tag fa-sm"></i> Bits and Pieces</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <hr> <h2 id="what-is-latin-hypercube-sampling">What is Latin Hypercube Sampling?</h2> <p>Imagine you’re standing over a large chessboard, each square representing a potential outcome of some experiment. The squares are spread out, spanning the entire board, and the goal is to gather a sample of outcomes that gives you the best possible understanding of the whole chessboard—not just a corner, not just a few scattered patches, but everywhere. Latin Hypercube Sampling (LHS) is a smart way to do this, ensuring that each row and column of the board has exactly one selected square. It’s like a carefully orchestrated game where you end up with one piece in every row and every column, giving you a complete sense of the landscape. In the world of data science, this chessboard metaphor expands into multidimensional space. Instead of just two dimensions—like the chessboard’s rows and columns—think of an entire universe of variables, each one adding a new dimension. If you’re trying to model something complex, like how different factors affect climate or how various inputs influence the outcome of an engineering system, you need a way to efficiently sample from all these different dimensions.</p> <p>That’s where LHS shines. Unlike random sampling, which might leave some regions underrepresented while others get chosen repeatedly, LHS spreads the samples evenly across each dimension. Think of it as ensuring every corner of the universe of possibilities gets its fair share of attention. Each sample is like a probe that’s perfectly positioned to gather information from every aspect of the system, without clustering too much in any one place.</p> <p>The key idea behind LHS is balance—the same kind of balance you see when picking one square from each row and column on the chessboard. In a higher-dimensional space, this means that every slice, or segment, of each variable range is covered, guaranteeing that the entire spectrum of potential values is represented. Whether you’re dealing with three variables or thirty, LHS keeps the sampling efficient and comprehensive, giving you a representative cross-section of all possible outcomes without redundancy or waste. This balanced sampling can be crucial in many practical applications. Imagine trying to predict the success of a new product launch by varying factors like price, marketing budget, and target audience. With LHS, you’re not just randomly throwing darts; you’re making sure that every aspect—from low budgets to high, from niche audiences to broad appeal—is represented in a structured way. The end result? A clearer picture of how each factor interacts, and ultimately, better insights and more informed decisions.</p> <p>LHS isn’t just about getting data—it’s about getting the right data, the kind that captures complexity without unnecessary repetition. In the chapters ahead, we’ll dive deeper into how LHS works in practice, explore its benefits, and compare it to other sampling methods, illustrating why this approach has become a favorite among statisticians and engineers alike.</p> <hr> <h2 id="why-do-we-need-latin-hypercube-sampling">Why Do We Need Latin Hypercube Sampling?</h2> <p>LHS is a powerful tool for efficiently understanding complex systems when resources are limited. In the real world, whether we are studying natural phenomena, building financial models, or designing new technology, we often face too many possible combinations of factors to analyze exhaustively. LHS provides a smart way to sample the most relevant data without having to examine every possibility.</p> <p>Think of tasting a big pot of vegetable soup. If you randomly scoop just once, you might get mostly broth or only one type of vegetable, missing the full flavor. LHS ensures that each spoonful represents every major ingredient, giving a balanced understanding of the whole pot. Similarly, LHS ensures that every part of a complex system is represented, giving us a clearer, more complete picture. This method is particularly useful in high-dimensional problems, like understanding energy consumption in a building, which depends on factors such as temperature, occupancy, lighting, and insulation. Random sampling might leave some factor combinations out, leading to gaps in understanding. LHS ensures that all relevant combinations are covered, making it easier to see the relationships without redundant or overlooked data. The efficiency of LHS is one of its biggest advantages. For instance, in modeling the effects of a new drug, with many variables like dosage and genetic markers, LHS allows for fewer, but strategically chosen, trials that still provide a comprehensive view. This means we can extract meaningful insights without the need for an overwhelming number of experiments.</p> <p>In practical applications, whether constrained by budget, time, or logistics, LHS proves invaluable. Engineers can use it to test a manageable number of car engine configurations, while scientists can employ it to study pollutant spread efficiently. LHS provides a strategic way to cover the landscape, ensuring no critical area is neglected.</p> <h2 id="how-does-latin-hypercube-sampling-work">How Does Latin Hypercube Sampling Work?</h2> <p>To truly understand LHS and appreciate its unique capabilities, we’ll delve into the mathematics underpinning it. Through a sequence of structured steps, we’ll see how LHS ensures efficient, balanced sampling in multidimensional space. This method systematically constructs sample points to provide a representative cross-section of complex systems, thereby capturing the essence of multidimensional data without unnecessary redundancy.</p> <h3 id="1-problem-setup">1. Problem Setup</h3> <p>Consider a \(d\)-dimensional parameter space where each parameter \(x_i\) can take values within a defined interval \([a_i, b_i]\). Our objective is to generate \(N\) distinct sample points \(x^{(1)}, x^{(2)}, \dots, x^{(N)}\), where each \(x^{(k)} = (x_1^{(k)}, x_2^{(k)}, \dots, x_d^{(k)})\) lies within this \(d\)-dimensional space. The challenge is to arrange these sample points such that they collectively cover the entire parameter space in a balanced and representative manner, avoiding clusters or sparse areas.</p> <h3 id="2-dividing-each-dimension-into-intervals">2. Dividing Each Dimension into Intervals</h3> <p>For each dimension \(x_i\), we begin by dividing the interval \([a_i, b_i]\) into \(N\) non-overlapping subintervals. Formally, we can define these intervals as:</p> \[[a_i, b_i] = \bigcup_{j=1}^N \left[ a_i + \frac{j-1}{N} (b_i - a_i), a_i + \frac{j}{N} (b_i - a_i) \right]\] <p>where each subinterval \(I\_{i,j}\) for dimension \(x_i\) is given by:</p> \[I_{i,j} = \left[ a_i + \frac{j-1}{N} (b_i - a_i), a_i + \frac{j}{N} (b_i - a_i) \right]\] <p>The length of each interval, \(\Delta x_i\), is consistent across \(x_i\):</p> \[\Delta x_i = \frac{b_i - a_i}{N}\] <p>This systematic partitioning ensures that each dimension \(x_i\) is split into \(N\) equal sections, which lays the groundwork for comprehensive sampling.</p> <h3 id="3-random-sampling-within-each-interval">3. Random Sampling within Each Interval</h3> <p>Within each subinterval \(I*{i,j}\) of dimension \(x_i\), we randomly select a point \(x*{i,j}\). This point can be represented mathematically as:</p> \[x_{i, j} = a_i + \frac{j-1}{N} (b_i - a_i) + U_{i,j} \cdot \Delta x_i\] <p>where \(U*{i,j} \sim \text{Uniform}(0,1)\) represents a uniformly distributed random variable within \([0,1]\). This formulation ensures that \(x*{i,j}\) falls randomly within the subinterval \(I\_{i,j}\), providing a sample point that respects the interval boundaries.</p> <h3 id="4-constructing-multidimensional-sample-points">4. Constructing Multidimensional Sample Points</h3> <p>To generate the complete set of \(N\) sample points in \(d\)-dimensional space, we must combine these dimension-specific sample points. This is done by assigning each sample from \(x_i\) to a unique subinterval in each dimension using a random permutation function \(\pi_i\). The permutation \(\pi_i\) for each dimension \(x_i\) randomly orders the indices \(\{1, 2, \dots, N\}\) such that each subinterval is represented exactly once.</p> <p>The \(k\)-th sample point in \(d\)-dimensional space is thus constructed as:</p> \[x^{(k)} = \left( x_{1, \pi_1(k)}, x_{2, \pi_2(k)}, \dots, x_{d, \pi_d(k)} \right)\] <p>This arrangement guarantees that each sample point spans a unique combination of subintervals across all dimensions, achieving an even spread and complete coverage of the parameter space.</p> <h3 id="5-proof-of-marginal-uniformity">5. Proof of Marginal Uniformity</h3> <p>One of the core strengths of LHS lies in its marginal uniformity. This property ensures that the samples are uniformly distributed along each individual dimension \(x_i\), even as they span multiple dimensions. Let’s delve into a formal explanation:</p> <ol> <li>Each dimension \(x*i\) is divided into \(N\) intervals \(I*{i,1}, I*{i,2}, \dots, I*{i,N}\), with a single sample \(x\_{i,j}\) taken from each interval.</li> <li>Each sample \(x\_{i,j}\) is drawn uniformly from within its interval, meaning that the probability of sampling any particular region within \([a_i, b_i]\) is evenly distributed.</li> <li>Consequently, for each dimension \(x_i\), the probability distribution of the sample points across intervals is uniform, with each subinterval receiving exactly one sample point.</li> </ol> <p>This uniformity across intervals ensures that the samples are well-distributed along each dimension, resulting in comprehensive and unbiased coverage of the space.</p> <h3 id="6-variance-reduction-in-latin-hypercube-sampling">6. Variance Reduction in Latin Hypercube Sampling</h3> <p>An essential advantage of LHS is its ability to reduce variance in the estimated outcomes, particularly when compared to simple random sampling (SRS). This reduction in variance leads to more accurate estimations with fewer samples. To illustrate this, we consider the variance of the sample mean \(\hat{f}\) when estimating the expectation \(\mathbb{E}[f(x)]\) for a function \(f(x)\) over our \(d\)-dimensional space.</p> <p>Given \(f(x)\), the sample mean \(\hat{f}\) based on \(N\) samples is:</p> \[\hat{f} = \frac{1}{N} \sum_{k=1}^N f(x^{(k)})\] <p>We can express the variance of \(\hat{f}\) as:</p> \[\text{Var}(\hat{f}) = \frac{1}{N^2} \sum_{k=1}^N \sum_{l=1}^N \text{Cov}(f(x^{(k)}), f(x^{(l)}))\] <p>In LHS, because each sample point \(f(x^{(k)})\) is drawn independently across distinct subintervals, the covariance \(\text{Cov}(f(x^{(k)}), f(x^{(l)}))\) for \(k \neq l\) is zero. This simplifies the variance expression to:</p> \[\text{Var}(\hat{f}) = \frac{1}{N^2} \sum_{k=1}^N \text{Var}(f(x^{(k)}))\] <h3 id="result-variance-reduction-in-lhs">Result: Variance Reduction in LHS</h3> <p>Since each sample \(f(x^{(k)})\) is uniformly distributed across the intervals, the variance in LHS is inherently reduced compared to simple random sampling. In SRS, the variance is:</p> \[\text{Var}_{\text{SRS}}(\hat{f}) = \frac{\sigma^2}{N}\] <p>where \(\sigma^2\) represents the population variance of \(f(x)\). In contrast, LHS ensures that each dimension’s intervals are well-covered, which results in:</p> \[\text{Var}_{\text{LHS}}(\hat{f}) \leq \frac{\sigma^2}{N}\] <p>This inequality demonstrates that LHS consistently achieves lower variance than simple random sampling, making it a more efficient and precise sampling method.</p> <hr> <h2 id="example-optimizing-a-drug-dosage-experiment-with-lhs">Example: Optimizing a Drug Dosage Experiment with LHS</h2> <p>To truly appreciate how LHS works, let’s dive into a practical example in drug dosage research. Suppose we’re conducting a study to understand how different drug doses, patient ages, and body weights affect blood concentration levels. Instead of relying on simple random sampling, which might overlook certain important combinations, LHS allows us to achieve balanced sampling across multiple dimensions, making the experiment both efficient and insightful.</p> <h3 id="experiment-setup-and-goals">Experiment Setup and Goals</h3> <p>In this study, we have three key variables:</p> <ol> <li> <strong>Dosage (\(x_1\))</strong>: Ranges from \([50, 200]\) mg.</li> <li> <strong>Age (\(x_2\))</strong>: Ranges from \([20, 80]\) years.</li> <li> <strong>Weight (\(x_3\))</strong>: Ranges from \([50, 100]\) kg.</li> </ol> <p>Our goal is to generate \(N = 5\) sample points that represent this multi-dimensional space well, ensuring each factor’s range is adequately covered. This approach will allow us to identify patterns without conducting an exhaustive set of tests.</p> <h3 id="step-1-dividing-each-dimension-into-intervals">Step 1: Dividing Each Dimension into Intervals</h3> <p>With \(N = 5\) samples, we divide each variable’s range into five non-overlapping intervals:</p> <ul> <li> <p><strong>Dosage (\(x_1\))</strong>: The range \([50, 200]\) mg is divided into five intervals of length \(\Delta x_1 = \frac{200 - 50}{5} = 30\) mg:</p> \[[50, 80], [80, 110], [110, 140], [140, 170], [170, 200]\] </li> <li> <p><strong>Age (\(x_2\))</strong>: The range \([20, 80]\) years is divided into five intervals of length \(\Delta x_2 = \frac{80 - 20}{5} = 12\) years:</p> \[[20, 32], [32, 44], [44, 56], [56, 68], [68, 80]\] </li> <li> <p><strong>Weight (\(x_3\))</strong>: The range \([50, 100]\) kg is divided into five intervals of length \(\Delta x_3 = \frac{100 - 50}{5} = 10\) kg:</p> \[[50, 60], [60, 70], [70, 80], [80, 90], [90, 100]\] </li> </ul> <p>This structured partitioning provides a foundation for balanced sampling within each dimension.</p> <h3 id="step-2-random-sampling-within-each-interval">Step 2: Random Sampling within Each Interval</h3> <p>Next, we randomly select a sample point within each subinterval. For example, within the first dosage interval \([50, 80]\), we select a random point \(x\_{1,1}\). We do the same for other intervals, ensuring a point is chosen within each range. This process guarantees that every segment of each variable’s range contributes to our sample set.</p> <p>Let’s say we get the following randomly chosen points for each dimension:</p> <ul> <li> <strong>Dosage (\(x_1\))</strong>: 63, 94, 125, 157, 189</li> <li> <strong>Age (\(x_2\))</strong>: 24, 39, 50, 63, 76</li> <li> <strong>Weight (\(x_3\))</strong>: 52, 66, 78, 85, 93</li> </ul> <h3 id="step-3-constructing-multi-dimensional-sample-points">Step 3: Constructing Multi-Dimensional Sample Points</h3> <p>To create our final five sample points in three-dimensional space, we combine these points by applying random permutations to each dimension. For example, we can randomly shuffle each dimension’s values, resulting in the following combinations:</p> <ul> <li> <strong>Dosage permutation</strong>: 125, 63, 189, 94, 157</li> <li> <strong>Age permutation</strong>: 63, 24, 76, 39, 50</li> <li> <strong>Weight permutation</strong>: 66, 78, 93, 52, 85</li> </ul> <p>Thus, our final sample points are:</p> \[(125, 63, 66)\] \[(63, 24, 78)\] \[(189, 76, 93)\] \[(94, 39, 52)\] \[(157, 50, 85)\] <h3 id="step-4-evaluating-the-balance-of-our-sample-set">Step 4: Evaluating the Balance of Our Sample Set</h3> <p>This arrangement ensures that each variable is evenly represented across its range. Every sample point combines different segments of each dimension, avoiding excessive clustering in any one area. Compared to simple random sampling, LHS guarantees a well-rounded representation of our parameter space, which is critical for accurately studying relationships between variables.</p> <h3 id="analyzing-the-results">Analyzing the Results</h3> <p>In this example, LHS allows us to effectively sample a three-dimensional space, covering a comprehensive range of dosage, age, and weight combinations with only five samples. This balanced approach gives us a holistic view of how these variables interact, helping researchers understand dosage effects across diverse patient profiles while minimizing experimental overhead.</p> <hr> <h2 id="real-world-applications-of-latin-hypercube-sampling">Real-World Applications of Latin Hypercube Sampling</h2> <p>LHS may sound like a tool for abstract math, but its practical impact is very real. Across engineering, environmental science, finance, healthcare, and energy modeling, LHS is a quietly transformative technique, allowing researchers to gain clear insights without drowning in data. Imagine trying to paint a detailed landscape but having only a handful of colors and brushstrokes to work with—LHS is like using those few strokes in exactly the right places to capture the whole scene with remarkable accuracy. Here’s how LHS works its magic across different fields.</p> <p>In engineering, for example, LHS helps streamline design and testing. Think of a car manufacturer simulating thousands of design combinations to improve performance under diverse conditions like temperature, load, and speed. Instead of running endless trials, LHS allows engineers to test a fraction of those designs in a structured way, covering the full range of conditions without redundancy. The result? They get the insights needed to enhance performance with far fewer tests, saving time and resources without sacrificing precision.</p> <p>Environmental science is another area where LHS is indispensable. Imagine trying to model how pollutants might spread across a city. Factors like wind speed, direction, and geographic features all interact to shape pollution patterns. With LHS, researchers can simulate these combinations in a balanced way, ensuring that different scenarios are well represented without oversampling any particular case. This approach not only sharpens predictions but also provides critical insights for health policies and urban planning—essential when resources are tight, but accuracy is crucial.</p> <p>Finance is yet another domain where LHS proves its worth, especially in risk analysis. Financial analysts need to understand how a portfolio might behave across a range of market conditions—interest rates, currency fluctuations, inflation, and so on. Rather than randomly selecting scenarios, LHS strategically samples across these factors, capturing both typical and extreme market conditions. This balanced approach provides a clearer risk profile and enables better-informed investment decisions, all while keeping data requirements manageable.</p> <p>In healthcare, LHS is a valuable ally in clinical trials and biomedical research. Imagine testing a new drug across diverse patient characteristics like age, genetic profile, and lifestyle. Testing every combination is impossible, so LHS helps researchers select a representative set of patient scenarios. By covering each variable without redundancy, LHS ensures that no group is overlooked, giving a comprehensive view of the drug’s impact across different demographics, often revealing critical insights early on.</p> <p>Even energy modeling for buildings benefits from LHS. When designing sustainable buildings, architects need to know how energy usage changes based on insulation, occupancy, weather, and other factors. LHS allows for sampling across these variables in a way that efficiently covers the range of possible conditions. By using LHS to model these combinations, analysts can optimize energy efficiency without testing every single scenario, resulting in smarter, greener design choices.</p> <p>In each of these fields, LHS is the secret ingredient that transforms limited samples into broad, balanced insights, ensuring that complex systems are thoroughly represented without overwhelming resources. It’s a perfect example of sampling smarter, not harder, proving that sometimes, a carefully chosen subset can be just as powerful as an exhaustive dataset. As data-driven decisions become more central to progress, LHS is one tool that ensures those decisions are both efficient and well-informed.</p> <hr> <h2 id="limitations-of-latin-hypercube-sampling">Limitations of Latin Hypercube Sampling</h2> <p>While LHS is a remarkably efficient method for capturing multidimensional data, it has limitations, particularly when dealing with high-dimensional spaces and dynamic systems. These challenges underscore that even advanced sampling techniques like LHS must sometimes be augmented or adapted to maintain efficiency and accuracy.</p> <h3 id="computational-demands-in-high-dimensions">Computational Demands in High Dimensions</h3> <p>One of the primary challenges with LHS arises in high-dimensional spaces. As the number of dimensions \(d\) grows, the complexity of generating \(N\) samples with balanced coverage across each dimension increases significantly. In lower-dimensional spaces, LHS achieves a clear advantage by ensuring that every interval in each dimension is represented. However, as \(d\) rises, this method begins to experience what’s known as the “curse of dimensionality,” where the sample space becomes exponentially large.</p> <p>To understand this more formally, consider that LHS divides each dimension’s interval into \(N\) equal parts, requiring \(N^d\) unique combinations to ensure complete coverage in the \(d\)-dimensional space. However, practical constraints often limit the total number of samples \(N\), leading to fewer possible combinations in the high-dimensional setting, which means that not all regions of the space are sampled as evenly. When the sampling coverage is incomplete, the variance reduction properties of LHS also diminish. The variance of a sample mean \(\hat{f}\) from LHS in high-dimensional spaces approximates as:</p> \[\text{Var}_{\text{LHS}}(\hat{f}) \approx \frac{\sigma^2}{N} \cdot \left( 1 + \frac{d - 1}{N} \right)\] <p>where \(\sigma^2\) is the population variance. This variance formula highlights that as \(d\) approaches \(N\), variance grows, and LHS’s advantage over simple random sampling (SRS) begins to diminish. In high-dimensional scenarios, achieving a representative sample with LHS can require exponentially more points to maintain the same precision, potentially making it less efficient than anticipated.</p> <h3 id="challenges-with-dynamic-systems">Challenges with Dynamic Systems</h3> <p>Another notable limitation of LHS lies in its static nature, which can be less effective for systems where variables have time-dependent relationships or feedback loops. LHS operates under the assumption that each variable can be sampled independently within its interval, which is reasonable for many static or quasi-static systems. However, in dynamic systems—such as those seen in financial markets, climate models, or real-time simulations—dependencies between variables often evolve over time, meaning the state of one variable may directly influence the others.</p> <p>For example, in a climate model where temperature, humidity, and wind speed are interdependent and change over time, simply sampling each dimension independently may miss critical interdependencies. Mathematically, if we denote a system state at time \(t\) as \(\mathbf{x}(t) = (x_1(t), x_2(t), \dots, x_d(t))\), then dynamic relationships between variables \(x_i(t)\) might require joint distribution sampling, something that LHS in its classical form doesn’t inherently accommodate.</p> <p>For dynamic models, we would ideally sample from the conditional distributions \(P(x*i(t) \vert x*{-i}(t))\), where \(x\_{-i}(t)\) represents the set of all other variables at time \(t\). However, traditional LHS treats each dimension independently, lacking the ability to conditionally update samples based on evolving states of other variables. As a result, alternative sampling techniques—such as sequential Monte Carlo (SMC) or particle filtering, which adapt to these dependencies—are often more appropriate for dynamic systems.</p> <h3 id="addressing-dependencies-and-dimensionality-constraints">Addressing Dependencies and Dimensionality Constraints</h3> <p>One way to address these limitations is by hybridizing LHS with other sampling techniques. For high-dimensional spaces, combining LHS with stratified sampling or Sobol sequences can mitigate the curse of dimensionality, ensuring better coverage in each dimension without requiring an impractical number of samples. In dynamic systems, integrating LHS with adaptive sampling techniques, where the sample distribution updates based on real-time data, may offer a way to retain the efficiency of LHS while accommodating evolving dependencies.</p> <hr> <h2 id="demo">Demo</h2> <p>Here’s a demonstration of LHS across different dimensions. In 2D, we see LHS distributing sample points evenly across the grid, ensuring each part of the space is represented. In 3D, this principle extends gracefully, capturing a well-balanced spread across all three dimensions. Finally, in 4D, we employ dimensionality reduction to visualize the sampling density, revealing how LHS continues to provide comprehensive coverage even in complex, multi-dimensional settings.</p> <blockquote> <p>Updated on June 22, 2024: Additionally, the PCA method used for dimensionality reduction in 4D sampling is detailed with examples in <a href="https://shuhongdai.github.io/blog/2024/Correlation_Coefficients/#pca-extracting-linear-patterns">our latest blog post</a>.</p> </blockquote> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts_img/2024-05-03/2d-480.webp 480w,/assets/posts_img/2024-05-03/2d-800.webp 800w,/assets/posts_img/2024-05-03/2d-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts_img/2024-05-03/2d.png" class="img-fluid" width="600" height="400" alt="2d" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts_img/2024-05-03/3d-480.webp 480w,/assets/posts_img/2024-05-03/3d-800.webp 800w,/assets/posts_img/2024-05-03/3d-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts_img/2024-05-03/3d.png" class="img-fluid" width="600" height="400" alt="3d" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts_img/2024-05-03/4d-480.webp 480w,/assets/posts_img/2024-05-03/4d-800.webp 800w,/assets/posts_img/2024-05-03/4d-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts_img/2024-05-03/4d.png" class="img-fluid" width="600" height="400" alt="4d" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span> <span class="n">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">qmc</span>

<span class="c1"># Set global Seaborn style for consistent visualization
</span><span class="n">sns</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="sh">"</span><span class="s">whitegrid</span><span class="sh">"</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="sh">"</span><span class="s">muted</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Number of samples and different dimensions to illustrate LHS sampling
</span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">dimensions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>

<span class="c1"># Function to generate Latin Hypercube Sampling points
</span><span class="k">def</span> <span class="nf">generate_lhs_samples</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
    <span class="n">sampler</span> <span class="o">=</span> <span class="n">qmc</span><span class="p">.</span><span class="nc">LatinHypercube</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">.</span><span class="nf">random</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sample</span>

<span class="c1"># Function to reduce dimensions using PCA (for high-dimensional data)
</span><span class="k">def</span> <span class="nf">reduce_dimension</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="nc">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pca</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Plotting 2D LHS samples
</span><span class="k">def</span> <span class="nf">plot_2d_lhs</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">2D LHS Sampling</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">blue</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Dimension 1</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Dimension 2</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Plotting 3D LHS samples with a 3D perspective
</span><span class="k">def</span> <span class="nf">plot_3d_lhs</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">3D LHS Sampling</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="sh">'</span><span class="s">3d</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Create 3D projection
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">samples</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">green</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Dimension 1</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Dimension 2</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_zlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Dimension 3</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Plotting 4D LHS samples reduced to 2D with density map
</span><span class="k">def</span> <span class="nf">plot_4d_lhs_with_density</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">4D LHS Sampling (PCA Reduced)</span><span class="sh">"</span><span class="p">):</span>
    <span class="c1"># Apply PCA to reduce the 4D data to 2D
</span>    <span class="n">reduced_samples</span> <span class="o">=</span> <span class="nf">reduce_dimension</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">reduced_samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">reduced_samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="c1"># Plot density heatmap using kdeplot
</span>    <span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">"</span><span class="s">Blues</span><span class="sh">"</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="c1"># Overlay the scatter plot for sampled points
</span>    <span class="n">sns</span><span class="p">.</span><span class="nf">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">red</span><span class="sh">"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">PCA Dimension 1</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">PCA Dimension 2</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Loop through the specified dimensions and generate the corresponding plots
</span><span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">dimensions</span><span class="p">:</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="nf">generate_lhs_samples</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Plot for 2D LHS sampling
</span>        <span class="nf">plot_2d_lhs</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">2D LHS Sampling</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="c1"># Plot for 3D LHS sampling with 3D view
</span>        <span class="nf">plot_3d_lhs</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">3D LHS Sampling</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="c1"># Plot for 4D LHS sampling after PCA reduction with density visualization
</span>        <span class="nf">plot_4d_lhs_with_density</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">4D LHS Sampling (PCA Reduced)</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <hr> <h2 id="wrapping-it-all-up">Wrapping It All Up</h2> <p>LHS is, without a doubt, an impressive technique. It’s one of those methods that shows just how much smarter sampling can be than a simple “grab a few random points and hope for the best” approach. By strategically covering each dimension and ensuring no corner of our data space is left unexplored, LHS brings precision and balance to the chaotic world of complex systems. Whether you’re testing car engines, predicting financial risk, modeling climate change, or designing clinical trials, LHS has a unique knack for extracting the most insight with the least effort. It’s efficiency and elegance wrapped into one neat package.</p> <p>That said, LHS is not a cure-all. As we explored, it starts to stumble in high dimensions, where the dreaded curse of dimensionality can make even the most elegant sampling methods feel a bit sluggish. And when variables are in flux, like in dynamic systems, LHS’s simple structure can’t quite capture the dance of interdependencies over time. In those cases, it’s like trying to catch a shadow—by the time you sample one point, the system has already changed. But here’s the fun part about a method like LHS: it has this air of adaptability. While it might not suit every situation perfectly, it can be hybridized, adjusted, and even reinvented to suit new needs. I think that’s why it’s so appealing to both engineers and data scientists alike.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <p class="mb-2">Enjoy Reading This Article? Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/Rethinking-1/">Rethinking an Olefin Oligomerization from Three Years Ago – Chapter 1: Problem Statement and Some Initial Thoughts from Back Then</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/Rethinking-0/">Rethinking an Olefin Oligomerization from Three Years Ago – Chapter 0: Preface</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/Proofs-for-Some-Properties/">A Sketch of Proofs for Some Properties of Multivariate Gaussian Distribution</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/multivariate_Gaussian_distribution/">Is the Transition from Univariate to Multivariate Gaussian Distribution Linear?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/Correlation_Coefficients/">A Supplementary Discussion on Correlation Coefficients</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Shuhong Dai. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/tabs.min.js?b8748955e1076bbe0dabcf28f2549fdc"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"post-rethinking-an-olefin-oligomerization-from-three-years-ago-chapter-1-problem-statement-and-some-initial-thoughts-from-back-then",title:"Rethinking an Olefin Oligomerization from Three Years Ago \u2013 Chapter 1: Problem Statement...",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2024/Rethinking-1/"}},{id:"post-rethinking-an-olefin-oligomerization-from-three-years-ago-chapter-0-preface",title:"Rethinking an Olefin Oligomerization from Three Years Ago \u2013 Chapter 0: Preface",description:"Perhaps I assumed, rather simplistically, that a mathematical modeling competition would primarily demand mathematical rigor, with little reliance on actual chemistry knowledge (an assumption that proved largely correct). Or perhaps I dismissed it as a straightforward data analysis exercise...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Rethinking-0/"}},{id:"post-a-sketch-of-proofs-for-some-properties-of-multivariate-gaussian-distribution",title:"A Sketch of Proofs for Some Properties of Multivariate Gaussian Distribution",description:"When we diagonalize the covariance matrix, we essentially rotate the space such that the axes align with the principal directions of variation...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Proofs-for-Some-Properties/"}},{id:"post-is-the-transition-from-univariate-to-multivariate-gaussian-distribution-linear",title:"Is the Transition from Univariate to Multivariate Gaussian Distribution Linear?",description:"Now that we have the foundation in place, let\u2019s shift gears and consider the generalization of the univariate Gaussian to higher dimensions. In the multivariate case, we are no longer dealing with a single random variable, but rather a vector of random variables...",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate_Gaussian_distribution/"}},{id:"post-a-supplementary-discussion-on-correlation-coefficients",title:"A Supplementary Discussion on Correlation Coefficients",description:"Yet covariance itself is sensitive to the original units of measurement, limiting its direct interpretability across different data scales...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Correlation_Coefficients/"}},{id:"post-an-introductory-look-at-covariance-and-the-mean-vector",title:"An Introductory Look at Covariance and the Mean Vector",description:"If the mean vector gives us a sense of location, then the covariance matrix gives us a sense of shape...",section:"Posts",handler:()=>{window.location.href="/blog/2024/An_Introductory_Look_at_Covariance_and_the_Mean_Vector/"}},{id:"post-sampling-smarter-unlocking-the-power-of-latin-hypercube-sampling",title:"Sampling Smarter: Unlocking the Power of Latin Hypercube Sampling",description:"Unlike random sampling, which might leave some regions underrepresented while others get chosen repeatedly...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Latin_Hypercube_Sampling/"}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-won-the-1st-prize-with-a-designed-four-switch-buck-boost-circuit-in-the-university-electronic-design-competition-sponsored-by-huawei",title:"Won the 1st prize with a designed four-switch buck-boost circuit in the university...",description:"",section:"News"},{id:"news-received-the-first-class-academic-scholarship",title:"Received the First-Class Academic Scholarship.",description:"",section:"News"},{id:"news-won-the-3rd-prize-for-problem-g-quot-non-contact-object-measurement-device-quot-at-the-8th-national-undergraduate-electronics-indesign-contest",title:"Won the 3rd prize for Problem G: &quot;Non-contact Object Measurement Device&quot; at the...",description:"",section:"News"},{id:"news-visited-the-key-laboratory-of-advanced-energy-traction-and-comprehensive-energy-saving-railway-industry-at-swjtu",title:"Visited the Key Laboratory of Advanced Energy Traction and Comprehensive Energy Saving Railway...",description:"",section:"News"},{id:"news-received-the-first-class-academic-scholarship",title:"Received the First-Class Academic Scholarship.",description:"",section:"News"},{id:"news-won-the-3rd-prize-in-problem-b-quot-ethanol-coupling-to-produce-c4-olefins-quot-at-the-30th-china-undergraduate-mathematical-contest-in-modeling",title:"Won the 3rd prize in Problem B: &quot;Ethanol Coupling to Produce C4 Olefins&quot;...",description:"",section:"News"},{id:"news-won-the-1st-prize-in-the-preliminary-national-round-of-the-5th-chinese-education-cup-mathematics-competition",title:"Won the 1st prize in the preliminary national round of the 5th Chinese...",description:"",section:"News"},{id:"news-won-the-2nd-prize-in-the-national-finals-of-the-5th-chinese-education-cup-mathematics-competition",title:"Won the 2nd prize in the national finals of the 5th Chinese Education...",description:"",section:"News"},{id:"news-won-the-1st-prize-at-the-provincial-level-in-the-13th-chinese-mathematics-competitions",title:"Won the 1st prize at the provincial level in the 13th Chinese Mathematics...",description:"",section:"News"},{id:"news-guided-the-quot-dual-car-following-system-quot-project-which-won-the-highest-award-the-quot-ti-cup-quot-in-the-10th-national-undergraduate-electronics-design-contest",title:"Guided the &quot;Dual-Car Following System&quot; project which won the highest award, the &quot;TI...",description:"",section:"News"},{id:"news-obtained-my-bachelor-39-s-degree-in-electrical-engineering",title:"Obtained my Bachelor&#39;s Degree in Electrical Engineering.",description:"",section:"News"},{id:"news-joined-the-distributed-systems-group-at-ncepu-to-pursue-my-master-39-s-degree-in-computer-science",title:"Joined the Distributed Systems Group at NCEPU to pursue my Master&#39;s degree in...",description:"",section:"News"},{id:"news-participated-in-world-robot-conference-2024-in-beijing",title:"Participated in World Robot Conference 2024 in Beijing.",description:"",section:"News"},{id:"news-a-paper-on-data-compression-https-ieeexplore-ieee-org-document-10376424-was-accepted-by-ieee-iot-journal",title:"[A paper on data compression](https://ieeexplore.ieee.org/document/10376424) was accepted by _IEEE IoT Journal_.",description:"",section:"News"},{id:"news-a-paper-on-energy-efficient-computing-https-www-sciencedirect-com-science-article-pii-s0140366423004802-via-3dihub-was-accepted-by-computer-communications",title:"[A paper on energy-efficient computing](https://www.sciencedirect.com/science/article/pii/S0140366423004802?via%3Dihub) was accepted by _Computer Communications_.",description:"",section:"News"},{id:"news-participated-in-microsoft-ai-day-beijing",title:"Participated in Microsoft AI Day Beijing.",description:"",section:"News"},{id:"news-a-paper-on-vehicle-road-cooperation-https-ieeexplore-ieee-org-document-10632106-was-accepted-by-ieee-iot-journal",title:"[A paper on vehicle-road cooperation](https://ieeexplore.ieee.org/document/10632106) was accepted by _IEEE IoT Journal_.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%61%69%73%68%75%68%6F%6E%67%30%32@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=lwCWmPUAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>