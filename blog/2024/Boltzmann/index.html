<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Maximal Entropy of the Boltzmann Distribution: A Quantum Perspective | Shuhong Dai </title> <meta name="author" content="Shuhong Dai"> <meta name="description" content="Specifically, in the classical limit (when Œ≤En &lt;&lt; 1), the quantum energy levels become very close to each other, and the partition function can be approximated by an integral over continuous energy states rather than a sum over discrete states. In this limit, the quantum Boltzmann distribution approaches the classical result..."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?6d57c5bac70ef6fae4bd96883a4eb4da"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shuhongdai.github.io/blog/2024/Boltzmann/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <link defer rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css"> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="https://tikzjax.com/v1/tikzjax.js" integrity="sha256-+1qyucCXRZJrCg3lm3KxRt/7WXaYhBid4/1XJRHGB1E=" crossorigin="anonymous"></script> <script src="/assets/js/typograms.js?63f3caa50c7a9624f953b3aec207afa6"></script> <script>document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-typograms").forEach(e=>{const t=e.textContent,n=e.parentElement.parentElement;let a=document.createElement("pre");a.classList.add("typogram");const d=create("\n"+t,.3,!1);a.appendChild(d),n.appendChild(a),n.removeChild(e.parentElement)})});</script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Maximal Entropy of the Boltzmann Distribution: A Quantum Perspective",
            "description": "Specifically, in the classical limit (when Œ≤En << 1), the quantum energy levels become very close to each other, and the partition function can be approximated by an integral over continuous energy states rather than a sum over discrete states. In this limit, the quantum Boltzmann distribution approaches the classical result...",
            "published": "November 28, 2024",
            "authors": [
              
              {
                "author": "Shuhong Dai",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "North China Electric Power University & AI Lab, CRRC Academy",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Shuhong</span> Dai </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Maximal Entropy of the Boltzmann Distribution: A Quantum Perspective</h1> <p>Specifically, in the classical limit (when Œ≤En &lt;&lt; 1), the quantum energy levels become very close to each other, and the partition function can be approximated by an integral over continuous energy states rather than a sum over discrete states. In this limit, the quantum Boltzmann distribution approaches the classical result...</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#maximizing-entropy-deriving-the-boltzmann-distribution">Maximizing Entropy: Deriving the Boltzmann Distribution</a> </div> <div> <a href="#quantum-canonical-ensemble-derivation-of-the-boltzmann-distribution">Quantum Canonical Ensemble Derivation of the Boltzmann Distribution</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>In statistical physics, the Boltzmann distribution is one of the most fundamental and widely applied concepts. It describes how particles in a system‚Äîwhether gas molecules, atoms, or even subatomic particles‚Äîdistribute themselves among different energy states in thermal equilibrium. This simple-looking equation, however, is far more than just a tool for calculating temperature or pressure; it links the microscopic, quantum behavior of individual particles to the macroscopic thermodynamic properties we observe in everyday life.</p> <p>But how exactly do we derive this distribution? While it‚Äôs commonly presented as a well-known result, the path to its formulation is anything but straightforward. The Boltzmann distribution doesn‚Äôt emerge from any single law of nature, but from a set of assumptions and principles. One of the key principles behind its derivation is the maximum entropy principle, a concept that originates in information theory but has profound implications in statistical mechanics.</p> <blockquote> <p><strong>Information theory must precede probability theory and not be based on it.</strong></p> <p>\(~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\) \(~~~~~~~~~~~~~~~~~~~~~~~\)by Andrey Nikolaevich Kolmogorov</p> </blockquote> <p>At its core, the maximum entropy principle suggests that, when constrained by known macroscopic quantities like energy or particle number, the most probable state of a system is the one that maximizes the system‚Äôs entropy. In simpler terms, the most likely distribution of particles is the one that reflects the greatest uncertainty about the system‚Äôs microscopic state, given the constraints we have. This approach not only provides a way to derive the Boltzmann distribution but also unites classical and quantum statistical mechanics.</p> <p>In classical systems, where particles can occupy continuous energy levels, the Boltzmann distribution directly describes how particles are spread across those levels. But in the quantum world, where particles are confined to discrete energy states, the situation becomes more complex. The introduction of the Quantum Canonical Ensemble allows us to extend the classical Boltzmann distribution into the quantum domain, where energy quantization and other quantum effects must be taken into account.</p> <p>In the following sections, we‚Äôll explore how the maximum entropy principle provides the key to deriving the Boltzmann distribution, and how it can be extended to the quantum realm through the Quantum Canonical Ensemble.</p> <blockquote> <p>Nov 28, 2024: Some of the quantum concepts mentioned in this article give me an excuse to shamelessly plug my upcoming paper, <strong>‚ÄúQuantum Reinforcement Learning for ü´£,‚Äù</strong> particularly the preliminary section. It‚Äôs currently undergoing major revision‚Äîstay tuned!</p> </blockquote> <hr> <h2 id="maximizing-entropy-deriving-the-boltzmann-distribution">Maximizing Entropy: Deriving the Boltzmann Distribution</h2> <p>In the quest to uncover the probability distribution that governs a system in thermodynamic equilibrium, we turn to the principle of maximum entropy. This elegant idea, first formulated in information theory, tells us that the best description of a system‚Äôs state is the one that maximizes uncertainty‚Äîsubject to the constraints we know about the system. In statistical mechanics, those constraints often relate to conserved quantities like total particle number or average energy.</p> <p>Let‚Äôs begin by considering a system with a set of discrete energy levels $ { \epsilon_i }_{i=1}^N $. Our goal is to find the probability distribution $ { p_i } $ that describes the likelihood of the system occupying each energy level $ \epsilon_i $, with the constraint that the total probability sums to one, and the system has a fixed average energy.</p> <h3 id="measuring-uncertainty">Measuring Uncertainty</h3> <p>To quantify this uncertainty, we use Shannon entropy. The entropy of a probability distribution $ { p_i } $ is defined as:</p> \[S = -k_B \sum_{i=1}^N p_i \ln p_i,\] <p>where $ k_B $ is the Boltzmann constant. This formula captures the degree of disorder or uncertainty within the system‚Äîthe more uncertain we are about the system‚Äôs microstate, the higher the entropy.</p> <blockquote> <p>Of course, you can also use other definitions or designed entropies, because the logarithmic function is not determined by the entropy itself, but rather by how we approximate entropy based on the variation properties of different functions according to personalized needs.</p> </blockquote> <p>Our task is to find the distribution $ { p_i } $ that maximizes this entropy, while also satisfying two important constraints:</p> <ol> <li> <p>Normalization: The total probability must sum to one:</p> \[\sum_{i=1}^N p_i = 1.\] </li> <li> <p>Energy constraint: The system‚Äôs average energy must be fixed at some value $ U $:</p> \[\langle E \rangle = \sum_{i=1}^N p_i \epsilon_i = U.\] </li> </ol> <h3 id="the-lagrange-multiplier-method">The Lagrange Multiplier Method</h3> <p>To incorporate these constraints, we use Lagrange multipliers. We want to maximize the entropy $ S $ subject to the above constraints, so we introduce two Lagrange multipliers, $ \alpha $ (for the normalization constraint) and $ \beta $ (for the energy constraint). We now define the Lagrangian functional $ \mathcal{L} $ as:</p> \[\mathcal{L} = -k_B \sum_{i=1}^N p_i \ln p_i - \alpha \left( \sum_{i=1}^N p_i - 1 \right) - \beta \left( \sum_{i=1}^N p_i \epsilon_i - U \right).\] <p>We seek the values of $ p_i $ that make $ \mathcal{L} $ stationary, which we do by differentiating with respect to $ p_i $ and setting the result equal to zero. The partial derivative of $ \mathcal{L} $ with respect to $ p_i $ is:</p> \[\frac{\partial \mathcal{L}}{\partial p_i} = -k_B (1 + \ln p_i) - \alpha - \beta \epsilon_i = 0.\] <p>Solving for $ p_i $, we get:</p> \[\ln p_i = -1 - \frac{\alpha}{k_B} - \frac{\beta}{k_B} \epsilon_i,\] <p>which simplifies to:</p> \[p_i = C e^{-\frac{\beta}{k_B} \epsilon_i},\] <p>where $ C $ is a constant to be determined later. This form suggests that the probability $ p_i $ is exponentially related to the energy $ \epsilon_i $, which is exactly what we expect from a system in equilibrium.</p> <blockquote> <p>For the details and principles of the Lagrange multiplier method, you can refer to any textbook on operations research and optimization.</p> <p>Here, we just used it as a tool for solving the problem. <strong>En r√©alit√©, j‚Äôai un v√©ritableement brillant raisonnement pour cette proposition, mais cette marge est bien trop √©troite pour le contenir.</strong> üòé</p> </blockquote> <h3 id="determining-the-constant--c-">Determining the Constant $ C $</h3> <p>To find the constant $ C $, we use the <strong>normalization condition</strong>. Summing over all states, we require that:</p> \[\sum_{i=1}^N p_i = 1.\] <p>Substituting the expression for $ p_i $, we obtain:</p> \[\sum_{i=1}^N C e^{-\frac{\beta}{k_B} \epsilon_i} = 1.\] <p>This implies that $ C $ must be:</p> \[C = \frac{1}{Z},\] <p>where $ Z $ is the partition function defined as:</p> \[Z = \sum_{i=1}^N e^{-\frac{\beta}{k_B} \epsilon_i}.\] <p>Thus, the probability distribution that maximizes entropy, subject to the constraints, is:</p> \[p_i = \frac{e^{-\frac{\beta}{k_B} \epsilon_i}}{Z}.\] <p>This is the Boltzmann distribution, where $ \beta $ is a constant related to the temperature $ T $ by $ \beta = \frac{1}{k_B T} $. This result tells us that the likelihood of the system being in a particular state is exponentially weighted by the energy of that state, with higher-energy states being exponentially less probable than lower-energy states at higher temperatures.</p> <h3 id="physical-interpretation">Physical Interpretation</h3> <p>The Boltzmann distribution not only maximizes the entropy but also satisfies the energy constraint: the average energy of the system $ \langle E \rangle $ is the weighted sum of the energies of the individual states, with the Boltzmann distribution providing the correct weighting. The factor $ \beta $ controls the distribution‚Äôs dependence on energy and temperature, with $ \beta $ decreasing as the temperature increases, meaning that at high temperatures, the system is more likely to occupy higher-energy states.</p> <p>We can also gain deeper insight into the partition function $ Z $. It plays a central role in thermodynamics, encapsulating all the information about the system‚Äôs statistical properties. In fact, the partition function is directly related to the Helmholtz free energy $ F $, which governs the system‚Äôs thermodynamic behavior:</p> \[F = -k_B T \ln Z.\] <p>From this, we can derive other thermodynamic quantities, like entropy $ S $ and internal energy $ U $, by differentiating $ F $ with respect to temperature or other variables.</p> <h3 id="demo">Demo</h3> <p>Now that we‚Äôve mathematically derived the Boltzmann distribution using the maximum entropy principle, let‚Äôs bring that theory to life with a simple Demo. The goal here is to simulate how the distribution behaves at different temperatures and visualize how particles are more likely to occupy higher energy states as temperature increases.</p> <p>We‚Äôll model a system with discrete energy levels $ \epsilon_i $ (let‚Äôs use values from 0 to 5 for simplicity). Our main task is to compute the probabilities $ p_i $ for each energy level using the Boltzmann distribution:</p> \[p_i = \frac{e^{-\frac{\beta}{k_B} \epsilon_i}}{Z},\] <p>where $ \beta = \frac{1}{k_B T} $ and $ Z $ is the partition function:</p> \[Z = \sum_{i=1}^N e^{-\frac{\beta}{k_B} \epsilon_i}.\] <d-code block="" language="python"> import numpy as np import matplotlib.pyplot as plt import seaborn as sns # Set up the energy levels (discrete levels) energy_levels = np.array([0, 1, 2, 3, 4, 5]) # Example energy levels # Function to calculate Boltzmann distribution probabilities def boltzmann_distribution(energy_levels, temperature): beta = 1 / temperature # Œ≤ = 1 / k_B T, assume k_B = 1 Z = np.sum(np.exp(-beta * energy_levels)) # Partition function probabilities = np.exp(-beta * energy_levels) / Z # Boltzmann distribution return probabilities # Set up the temperatures to explore temperatures = [0.5, 1, 2, 5, 10] # Different temperatures to visualize # Set up the plot plt.figure(figsize=(10, 6)) sns.set(style="whitegrid") # Plot the Boltzmann distribution for each temperature for T in temperatures: probabilities = boltzmann_distribution(energy_levels, T) plt.plot(energy_levels, probabilities, label=f"T = {T}", marker='o', linestyle='-', markersize=6) # Customize the plot plt.title('Boltzmann Distribution at Different Temperatures', fontsize=16) plt.xlabel('Energy Level $\epsilon_i$', fontsize=14) plt.ylabel('Probability $p_i$', fontsize=14) plt.legend(title="Temperature (T)", loc='upper right') plt.grid(True) plt.show() </d-code> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts_img/2024-11-28/Boltzmann%20Distribution%20at%20Different%20Temperatures-480.webp 480w,/assets/posts_img/2024-11-28/Boltzmann%20Distribution%20at%20Different%20Temperatures-800.webp 800w,/assets/posts_img/2024-11-28/Boltzmann%20Distribution%20at%20Different%20Temperatures-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts_img/2024-11-28/Boltzmann%20Distribution%20at%20Different%20Temperatures.png" class="img-fluid" width="600" height="400" alt="Boltzmann Distribution at Different Temperatures" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>What you‚Äôll notice is that at low temperatures (e.g., $ T = 0.5 $), the distribution is sharply peaked at the lowest energy level‚Äîmost particles occupy the ground state. As the temperature increases (e.g., $ T = 10 $), the distribution spreads out, and the probability of occupying higher energy states increases. This is the Boltzmann distribution in action: at higher temperatures, particles are more likely to be found in higher energy states because there is less exponential suppression of those states.</p> <hr> <h2 id="quantum-canonical-ensemble-derivation-of-the-boltzmann-distribution">Quantum Canonical Ensemble Derivation of the Boltzmann Distribution</h2> <p>After deriving the classical Boltzmann distribution using the maximum entropy principle, we‚Äôve arrived at a powerful tool for understanding systems in thermal equilibrium. But here‚Äôs where things get really interesting: what happens when we shift our attention from classical to quantum systems? Classical statistics, as we know, assumes that energy levels are continuous, particles behave as distinguishable entities, and the laws of thermodynamics apply seamlessly. However, quantum systems operate under different rules, with discrete energy levels, indistinguishable particles, and, crucially, quantum mechanical phenomena like superposition and entanglement.</p> <h3 id="from-classical-to-quantum">From Classical to Quantum</h3> <p>In classical systems, the energy levels are treated as continuous, and particles are distinguishable. For example, in classical thermodynamics, the system‚Äôs behavior is described by average quantities (like pressure, volume, and temperature) that emerge from statistical averages over all possible microstates. But when dealing with quantum systems, things get much more intricate.</p> <p>Quantum systems are governed by a Hilbert space, where the energy states are discrete, and the particles are indistinguishable. This means the states of the system are no longer described by simple averages but by a density operator. Furthermore, quantum systems obey the Pauli exclusion principle (for fermions) or Bose-Einstein statistics (for bosons), which impose additional constraints on how particles can occupy different energy states.</p> <p>In quantum statistical mechanics, we must therefore account for these discrete states and their probabilistic occupation. Rather than dealing with a smooth distribution over energy states, we deal with specific quantum states, each of which has a corresponding energy eigenvalue $ E_n $. These eigenstates $ \vert n \mathpunct{\rangle} $ can be occupied with different probabilities depending on the temperature, which leads us to the concept of the partition function and the density matrix.</p> <h3 id="the-quantum-partition-function">The Quantum Partition Function</h3> <p>In quantum statistical mechanics, the partition function plays a similar role to what it did in the classical derivation of the Boltzmann distribution. However, in quantum systems, we express this as a sum over all possible quantum states, each weighted by a factor related to its energy:</p> \[Z = \sum_n e^{- \beta E_n},\] <p>where $ Z $ is the quantum partition function, $ \beta = \frac{1}{k_B T} $ is the inverse temperature, and $ E_n $ are the energy eigenvalues of the system. This sum takes into account all possible quantum states, where the probability of being in a particular state $ \vert n \mathpunct{\rangle} $ depends on its energy $ E_n $.</p> <p>The density operator $ \hat{\rho} $, which describes the quantum state of the system, is given by:</p> \[\hat{\rho} = \frac{1}{Z} e^{-\beta \hat{H}},\] <p>where $ \hat{H} $ is the Hamiltonian operator (which encapsulates the total energy of the system). The density operator governs the probability distribution of the system‚Äôs quantum states, and we can calculate the probability $ P_n $ of finding the system in state $ \vert n \mathpunct{\rangle} $ as:</p> \[P_n = \langle n | \hat{\rho} | n \rangle = \frac{e^{- \beta E_n}}{Z}.\] <h3 id="deriving-the-quantum-boltzmann-distribution">Deriving the Quantum Boltzmann Distribution</h3> <p>Now that we have the quantum density matrix $ \hat{\rho} $, the next step is to derive the quantum version of the Boltzmann distribution. For a system in thermal equilibrium, the probability of the system occupying a particular quantum state $ |n \mathpunct{\rangle}$ with energy $ E_n $ is given by:</p> \[P_n = \frac{e^{- \beta E_n}}{Z}.\] <p>This is the same formula as the classical Boltzmann distribution, but with one crucial difference: it arises in a quantum context, where the states $ \vert n \mathpunct{\rangle} $ are discrete and represent the quantum states of the system. Importantly, the partition function $ Z $ accounts for the normalization of the system over all possible states, ensuring that the total probability sums to 1.</p> <p>In quantum systems, the partition function $ Z $ is not just a mathematical convenience‚Äîit‚Äôs a central thermodynamic quantity. It encapsulates all the thermal information of the system, allowing us to derive quantities such as the average energy, entropy, and even the free energy. The internal energy $ U $, for example, is given by:</p> \[U = \langle \hat{H} \rangle = \frac{1}{Z} \sum_n E_n e^{-\beta E_n}.\] <p>This quantity, $ U $, provides the average energy of the system, weighted by the Boltzmann factor $ e^{-\beta E_n} $. Similarly, the entropy $ S $ of the system can be derived from the density matrix, and is given by:</p> \[S = -k_B \sum_n P_n \ln P_n = k_B \left( \ln Z + \beta \langle E \rangle \right).\] <h3 id="recovering-the-classical-limit">Recovering the Classical Limit</h3> <p>At this point, we‚Äôve arrived at the <strong>quantum Boltzmann distribution</strong>:</p> \[P_n = \frac{e^{- \beta E_n}}{Z}.\] <p>But how do we connect this result to the classical case? The answer lies in the high-temperature limit. As temperature $T$ increases, the quantum system behaves more and more like a classical system. Specifically, in the classical limit (when $ \beta E_n \ll 1 $), the quantum energy levels become very close to each other, and the partition function can be approximated by an integral over continuous energy states rather than a sum over discrete states. In this limit, the quantum Boltzmann distribution approaches the classical result:</p> \[P_n \approx \frac{e^{-\beta E_n}}{Z_{\text{classical}}}.\] <p>This recovery of the classical Boltzmann distribution from the quantum framework illustrates the seamless transition from quantum to classical statistics as the temperature increases and the system becomes large.</p> <h3 id="demo-1">Demo</h3> <p>Now that we‚Äôve got a solid understanding of how the quantum Boltzmann distribution works, let‚Äôs see it in action. We‚Äôll simulate a system of particles that can occupy discrete energy levels, and use Python to calculate and plot the probability of each energy state at various temperatures.</p> <p>In quantum mechanics, things get interesting because energy levels are discrete. This means particles in a system can only occupy specific energy states. The Boltzmann distribution in this context gives us the probability of a system being in a particular state, and it‚Äôs influenced by temperature. The cooler the system, the more likely it is to find particles in the lower energy states. As the temperature rises, particles are more likely to occupy higher energy states.</p> <p>We‚Äôll work with a simple system of five energy levels, ranging from 0 to 4 (in arbitrary units), and observe how the distribution of particles shifts as we change the temperature.</p> <p>In the code, we define the energy levels and compute the Boltzmann distribution for different temperatures. The partition function $ Z $ normalizes the distribution, ensuring that the total probability across all states sums to 1. At each temperature, we calculate the probability of the system being in each energy state and plot it.</p> <d-code block="" language="python"> import numpy as np import matplotlib.pyplot as plt # Constants k_B = 1 # Boltzmann constant (arbitrary units) temperatures = [1, 5, 10, 20] # Temperature values (arbitrary units) energy_levels = np.array([0, 1, 2, 3, 4]) # Energy levels (arbitrary units) # Function to compute the quantum Boltzmann distribution def quantum_boltzmann_distribution(E, T): beta = 1 / (k_B * T) Z = np.sum(np.exp(-beta * E)) # Partition function P = np.exp(-beta * E) / Z # Quantum Boltzmann distribution return P, Z # Create the plot fig, ax = plt.subplots(figsize=(8, 6)) # Plot the probability distributions for different temperatures for T in temperatures: P, Z = quantum_boltzmann_distribution(energy_levels, T) ax.plot(energy_levels, P, label=f'T = {T} units (Z = {Z:.2f})') # Formatting the plot ax.set_xlabel('Energy Levels (E)', fontsize=14) ax.set_ylabel('Probability (P)', fontsize=14) ax.set_title('Quantum Boltzmann Distribution at Different Temperatures', fontsize=16) ax.legend(title="Temperature (T)") # Display the plot plt.grid(True) plt.tight_layout() plt.show() </d-code> <p>At low temperatures, the particles prefer the lower energy states, so you‚Äôll see a sharp peak at $ E = 0 $. As the temperature increases, the distribution flattens out, meaning particles are more evenly spread across the available energy states. At high temperatures, the system behaves almost classically, with probabilities becoming more uniform across the states.</p> <p>If you push the temperature high enough, the quantum effects start to blur out. The system behaves less quantum-mechanically and more classically‚Äîparticles are equally likely to be found in any state. This is where quantum and classical statistics start to converge, and the Boltzmann distribution recovers its classical form.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/posts_img/2024-11-28/Quantum%20Boltzmann%20Distribution%20at%20Different%20Temperatures'-480.webp 480w,/assets/posts_img/2024-11-28/Quantum%20Boltzmann%20Distribution%20at%20Different%20Temperatures'-800.webp 800w,/assets/posts_img/2024-11-28/Quantum%20Boltzmann%20Distribution%20at%20Different%20Temperatures'-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/posts_img/2024-11-28/Quantum%20Boltzmann%20Distribution%20at%20Different%20Temperatures'.png" class="img-fluid" width="600" height="400" alt="Quantum Boltzmann Distribution at Different Temperatures" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <hr> <h2 id="conclusion">Conclusion</h2> <p>Along the way, we explored how the seemingly simple concept of entropy can elegantly extend from classical to quantum systems, providing us with the tools to model everything from gas particles to quantum states in thermal equilibrium.</p> <p>Of course, I‚Äôll be the first to admit that this is far from a perfect or complete explanation. Some of the math might feel a bit rushed, and the logic may not always be as sharp as it should be. Frankly, I‚Äôm still wrapping my head around some of these ideas myself. So, if you‚Äôre an expert (or even if you‚Äôre not), feel free to call me out‚ÄîI‚Äôm sure there are plenty of rough edges that need smoothing over. This is a work in progress, not the final word. üåé</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2024 Shuhong Dai. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"post-maximal-entropy-of-the-boltzmann-distribution-a-quantum-perspective",title:"Maximal Entropy of the Boltzmann Distribution: A Quantum Perspective",description:"Specifically, in the classical limit (when \u03b2En &lt;&lt; 1), the quantum energy levels become very close to each other, and the partition function can be approximated by an integral over continuous energy states rather than a sum over discrete states. In this limit, the quantum Boltzmann distribution approaches the classical result...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Boltzmann/"}},{id:"post-a-sketch-of-proofs-for-some-properties-of-multivariate-gaussian-distribution",title:"A Sketch of Proofs for Some Properties of Multivariate Gaussian Distribution",description:"When we diagonalize the covariance matrix, we essentially rotate the space such that the axes align with the principal directions of variation...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Proofs-for-Some-Properties/"}},{id:"post-is-the-transition-from-univariate-to-multivariate-gaussian-distribution-linear",title:"Is the Transition from Univariate to Multivariate Gaussian Distribution Linear?",description:"Now that we have the foundation in place, let\u2019s shift gears and consider the generalization of the univariate Gaussian to higher dimensions. In the multivariate case, we are no longer dealing with a single random variable, but rather a vector of random variables...",section:"Posts",handler:()=>{window.location.href="/blog/2024/multivariate_Gaussian_distribution/"}},{id:"post-a-supplementary-discussion-on-correlation-coefficients",title:"A Supplementary Discussion on Correlation Coefficients",description:"Yet covariance itself is sensitive to the original units of measurement, limiting its direct interpretability across different data scales...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Correlation_Coefficients/"}},{id:"post-an-introductory-look-at-covariance-and-the-mean-vector",title:"An Introductory Look at Covariance and the Mean Vector",description:"If the mean vector gives us a sense of location, then the covariance matrix gives us a sense of shape...",section:"Posts",handler:()=>{window.location.href="/blog/2024/An_Introductory_Look_at_Covariance_and_the_Mean_Vector/"}},{id:"post-problem-dual-spaces-and-functional-analysis",title:"Problem \u2163: Dual Spaces and Functional Analysis",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/EC525_4/"}},{id:"post-sampling-smarter-unlocking-the-power-of-latin-hypercube-sampling",title:"Sampling Smarter: Unlocking the Power of Latin Hypercube Sampling",description:"Unlike random sampling, which might leave some regions underrepresented while others get chosen repeatedly...",section:"Posts",handler:()=>{window.location.href="/blog/2024/Latin_Hypercube_Sampling/"}},{id:"post-problem-group-theory",title:"Problem \u2162: Group Theory",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/EC525_3/"}},{id:"post-problem-linear-transformations",title:"Problem \u2161: Linear Transformations",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/EC525_2/"}},{id:"post-problem-vector-spaces",title:"Problem \u2160: Vector Spaces",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/EC525_1/"}},{id:"post-preface-motivation-and-overview",title:"Preface: Motivation and Overview",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/EC525_0/"}},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-won-the-1st-prize-with-a-designed-four-switch-buck-boost-circuit-in-the-university-electronic-design-competition-sponsored-by-huawei",title:"Won the 1st prize with a designed four-switch buck-boost circuit in the university...",description:"",section:"News"},{id:"news-received-the-first-class-academic-scholarship",title:"Received the First-Class Academic Scholarship.",description:"",section:"News"},{id:"news-won-the-3rd-prize-for-problem-g-quot-non-contact-object-measurement-device-quot-at-the-8th-national-undergraduate-electronics-indesign-contest",title:"Won the 3rd prize for Problem G: &quot;Non-contact Object Measurement Device&quot; at the...",description:"",section:"News"},{id:"news-visited-the-key-laboratory-of-advanced-energy-traction-and-comprehensive-energy-saving-railway-industry-at-swjtu",title:"Visited the Key Laboratory of Advanced Energy Traction and Comprehensive Energy Saving Railway...",description:"",section:"News"},{id:"news-received-the-first-class-academic-scholarship",title:"Received the First-Class Academic Scholarship.",description:"",section:"News"},{id:"news-won-the-3rd-prize-in-problem-b-quot-ethanol-coupling-to-produce-c4-olefins-quot-at-the-30th-china-undergraduate-mathematical-contest-in-modeling",title:"Won the 3rd prize in Problem B: &quot;Ethanol Coupling to Produce C4 Olefins&quot;...",description:"",section:"News"},{id:"news-won-the-1st-prize-in-the-preliminary-national-round-of-the-5th-chinese-education-cup-mathematics-competition",title:"Won the 1st prize in the preliminary national round of the 5th Chinese...",description:"",section:"News"},{id:"news-won-the-2nd-prize-in-the-national-finals-of-the-5th-chinese-education-cup-mathematics-competition",title:"Won the 2nd prize in the national finals of the 5th Chinese Education...",description:"",section:"News"},{id:"news-won-the-1st-prize-at-the-provincial-level-in-the-13th-chinese-mathematics-competitions",title:"Won the 1st prize at the provincial level in the 13th Chinese Mathematics...",description:"",section:"News"},{id:"news-guided-the-quot-dual-car-following-system-quot-project-which-won-the-highest-award-the-quot-ti-cup-quot-in-the-10th-national-undergraduate-electronics-design-contest",title:"Guided the &quot;Dual-Car Following System&quot; project which won the highest award, the &quot;TI...",description:"",section:"News"},{id:"news-obtained-my-bachelor-39-s-degree-in-electrical-engineering",title:"Obtained my Bachelor&#39;s Degree in Electrical Engineering.",description:"",section:"News"},{id:"news-joined-the-distributed-systems-group-at-ncepu-to-pursue-my-master-39-s-degree-in-computer-science",title:"Joined the Distributed Systems Group at NCEPU to pursue my Master&#39;s degree in...",description:"",section:"News"},{id:"news-participated-in-world-robot-conference-2024-in-beijing",title:"Participated in World Robot Conference 2024 in Beijing.",description:"",section:"News"},{id:"news-a-paper-on-data-compression-for-transportation-https-ieeexplore-ieee-org-document-10376424-was-accepted-by-ieee-iot-journal",title:"[A paper on data compression for transportation](https://ieeexplore.ieee.org/document/10376424) was accepted by _IEEE IoT Journal_....",description:"",section:"News"},{id:"news-a-paper-on-energy-efficient-computing-https-www-sciencedirect-com-science-article-pii-s0140366423004802-via-3dihub-was-accepted-by-computer-communications",title:"[A paper on energy-efficient computing](https://www.sciencedirect.com/science/article/pii/S0140366423004802?via%3Dihub) was accepted by _Computer Communications_.",description:"",section:"News"},{id:"news-participated-in-microsoft-ai-day-beijing",title:"Participated in Microsoft AI Day Beijing.",description:"",section:"News"},{id:"news-a-paper-on-vehicle-road-cooperation-https-ieeexplore-ieee-org-document-10632106-was-accepted-by-ieee-iot-journal",title:"[A paper on vehicle-road cooperation](https://ieeexplore.ieee.org/document/10632106) was accepted by _IEEE IoT Journal_.",description:"",section:"News"},{id:"news-i-m-thrilled-to-announce-the-release-of-texhelper-https-pypi-org-project-texhelper-a-python-library-designed-to-optimize-and-beautify-tex-code-texhelper-makes-managing-your-latex-based-projects-easier-and-more-elegant-the-project-is-open-source-and-available-on-github-https-github-com-shuhongdai-texhelper-check-it-out",title:"\ud83c\udf89\ud83c\udf89\ud83c\udf89 I\u2019m thrilled to announce the release of [TexHelper](https://pypi.org/project/texhelper/), a Python library designed...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%61%69%73%68%75%68%6F%6E%67%30%32@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=lwCWmPUAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>